{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Advanced statistics: Statistical modelling","text":""},{"location":"#teachers","title":"Teachers","text":"<p>Rachel Marcone</p> <p>Thomas Zwahlen</p> <p>Joao Lourenco</p> <p>Tania Wyss</p>"},{"location":"#general-learning-outcomes","title":"General learning outcomes","text":"<p>At the end of this course, participants will be able to:</p> <ul> <li>identify the appropriate model to analyze a dataset;</li> <li>fit the chosen model using R;</li> <li>assess the fit of the model, as well as its limitations.</li> <li>Perform regularization or cross-validation</li> </ul>"},{"location":"#learning-outcomes-explained","title":"Learning outcomes explained","text":"<p>To reach the general learning outcomes above, we have set a number of smaller learning outcomes. Each chapter starts with these smaller learning outcomes. Use these at the start of a chapter to get an idea what you will learn. Use them also at the end of a chapter to evaluate whether you have learned what you were expected to learn.</p>"},{"location":"#learning-experiences","title":"Learning experiences","text":"<p>To reach the learning outcomes we will use lectures, exercises and group work. During exercises, you are free to discuss with other participants. During lectures, focus on the lecture only.</p>"},{"location":"#exercises","title":"Exercises","text":"<p>Each block has practical work involved. Some more than others. The practicals are subdivided into chapters, and we\u2019ll have a (short) discussion after each chapter. Some answers to the practicals are incorporated, but they are hidden. Do the exercise first by yourself, before checking out the answer. If your answer is different from the answer in the practicals, try to figure out why they are different.</p>"},{"location":"#asking-questions","title":"Asking questions","text":"<p>During lectures, you are encouraged to raise your hand if you have questions.</p>"},{"location":"bonus_code/","title":"Bonus code","text":""},{"location":"bonus_code/#bonus-code","title":"Bonus code","text":"<p>The following code was added thanks to questions from course participants of past sessions. They might be useful for you too.</p> <p>Download slides</p>"},{"location":"bonus_code/#linear-regression-using-model-selection","title":"Linear Regression using model selection","text":""},{"location":"bonus_code/#linear-regression","title":"Linear regression","text":"<pre><code>library(MASS)\n\ndata(birthwt)\nsummary(birthwt)\n\nhelp(birthwt)\n\ncolnames(birthwt)\ncolnames(birthwt) &lt;- c(\"birthwt.below.2500\", \"mother.age\",\"mother.weight\", \"race\",\n                       \"smoking.status\", \"nb.previous.prem.labor\",  \"hypertension\", \n                       \"uterine.irrit\",\"nb.physician.visits\", \"birthwt.grams\")\n\nstr(birthwt)\nsummary(birthwt)\nbirthwt$race &lt;- as.factor(birthwt$race)\nstr(birthwt)\nsummary(birthwt)\n</code></pre>"},{"location":"bonus_code/#model-selection","title":"Model selection","text":"<pre><code>library(leaps) \n\nbest_subset &lt;- regsubsets(birthwt.grams ~ . - birthwt.below.2500, data = birthwt, nvmax = 8)\nresults &lt;- summary(best_subset)\n\n# Adjusted R-squared\nplot(results$adjr2, xlab = \"Number of Variables\", ylab = \"Adjusted R-squared\", type = \"l\")\n# Residual sum of squares for each model\nplot(results$rss, xlab = \"Number of Variables\", ylab = \"RSS\", type = \"l\")\n# R-squared\nplot(results$rsq, xlab = \"Number of Variables\", ylab = \"R-squared\", type = \"l\")\n\nwhich.max(results$adjr2)\n</code></pre>"},{"location":"bonus_code/#model-selection-using-the-validation-set-approach","title":"Model selection using the validation set approach","text":"<pre><code>set.seed(1)\ntrain &lt;- sample(c(TRUE, FALSE), size = nrow(birthwt), rep = TRUE)\ntest &lt;- (!train)\n\nbest_subset_train &lt;- regsubsets(birthwt.grams ~ . - birthwt.below.2500, data = birthwt[train ,], nvmax = 8)\ntest_mat &lt;- model.matrix(birthwt.grams ~ . - birthwt.below.2500, data = birthwt[test,])\n\nval_errors  &lt;- rep(NA , 8)\nfor(i in 1:8){\n  coefi = coef(best_subset_train, id = i)\n  pred = test_mat[,names(coefi)]%*%coefi\n  val_errors[i] = mean((birthwt$birthwt.grams[test] - pred)^2)\n}\nwhich.min(val_errors)\n</code></pre>"},{"location":"course_schedule/","title":"Course schedule","text":"<p>Note</p> <p>Apart from the starting time the time schedule is indicative. Because we can not plan a course by the minute, in practice the time points will deviate. </p>"},{"location":"course_schedule/#day-1","title":"Day 1","text":"block start end subject introduction 9:15 AM 9:30 AM Simple and multiple linear regression block 1 9:30 AM 10:30 AM 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM"},{"location":"course_schedule/#day-2","title":"Day 2","text":"block start end subject block 1 9:00 AM 10:30 AM Generalized linear models 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM Further exercises 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM Further exercises"},{"location":"course_schedule/#day-3","title":"Day 3","text":"block start end subject block 1 9:00 AM 10:30 AM Mixed-effects linear models 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM Longitudinal data analysis 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM"},{"location":"course_schedule/#day-4","title":"Day 4","text":"block start end subject block 1 9:00 AM 10:30 AM Performance and Regularizations 10:30 AM 11:00 AM BREAK block 2 11:00 AM 12:30 PM 12:30 PM 1:30 PM BREAK block 3 1:30 PM 3:00 PM 3:00 PM 3:30 PM BREAK block 4 3:30 PM 5:00 PM"},{"location":"day1/","title":"Simple, multiple linear regression and beyond","text":"<p>In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises.</p>"},{"location":"day1/#learning-outcomes-of-the-day","title":"Learning outcomes of the day","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Do simple and multiple linear regression</li> <li>Understand if the data would be suited for a linear regression</li> <li>Understand the output of a linear regression</li> <li>Understand the interaction term </li> <li>Find outliers and influential points </li> <li>Diagnostics on a model</li> <li>Simple transformation on the data to be able to use a linear regression</li> <li>Still in the case of a continuous predictor, going beyond linear regression</li> <li>Including Splines, polynomial functions, step functions.</li> </ul> <p>Slides of lectures: Download slides Intro Lecture</p> <p>Download slides Morning Lecture</p> <p>Download slides Afternoon Lecture</p> <p>Data for exercises:</p> <p>Download full data for the week</p>"},{"location":"day1/#source-of-data","title":"Source of data","text":"<p>We created a (non-existing) class of students for which you have some information. The name of the students, their gender, the age, the height and the weight of those adolescent students are provided. </p> <p>Before starting the exercises, set the working directory to where you have downloaded and unzipped the data folder with the files for the exercises  and load the necessary packages. </p> <p>Warning</p> <p>When using setwd(), change the path within quotes to where you have saved the data for the exercises. Make sure to always be in the right folder for the exercises.</p> <pre><code># Change the path here:\nsetwd(\"/path/to/whereDataFolderIsSaved/\")\n\n# Load the libraries needed for this exercise\n# Here only plotting libraries are needed\n\nlibrary(ggplot2)\nlibrary(car)\n</code></pre>"},{"location":"day1/#simple-linear-models-and-simple-multiple-linear-models","title":"Simple linear models and simple multiple linear models","text":""},{"location":"day1/#the-class-data-set","title":"The class data set","text":"<p>Import the data into your R session and explore its structure: what are the different columns corresponding to? Is the table in a usable format ?</p> <pre><code># Load the class table\nclass &lt;- read.table(\"exercises/class.txt\")\n\n# Have a look\nsummary(class[,-1])\n</code></pre> <p>Here we see a problem for the Gender, what is it ? Can you correct for it ?</p> Answer <pre><code>#Gender is a \"character\" variable and should be a factor\nclass$Gender[class$Gender == \"F\"] &lt;- 0\nclass$Gender[class$Gender == \"M\"] &lt;- 1\nclass$Gender &lt;- as.numeric(class$Gender)\n</code></pre> <p>Now we make use of the function pairs (do not know it? look it up with the help!). We then create a simple linear model using Age to describe the height of our students, have a look at the summary of this regression, then plot it.</p> <pre><code>pairs(class[,-1])\n</code></pre> <pre><code>model &lt;- lm(Height ~ Age, data=class)\nsummary(model)\nplot(class$Age, class$Height, xlim=c(0,20), ylim=c(0,200))\nabline(model, col=\"red\", lwd=2)\n#putting the xlim to 0 we can visually see the intercept\n</code></pre> <p>Are there any influencial points ? Do they have something special? What do you do with them ?</p> <pre><code>hat &lt;- lm.influence(model)\nplot(hat$hat)\n\ncar::influencePlot(model, xlab=\"Hat-Values\", ylab=\"Studentized Residuals\")\n</code></pre> <p>Use the predict function to calculate a confidence interval.</p> <pre><code>new_age &lt;- seq(11, 16, by=0.25)\nplot(class$Age, class$Height,pch=20,col=\"black\")\npoints(class$Age[c(7,19)],class$Height[c(7,19)],col=\"green\")\nconf_interval &lt;- predict.lm(model, newdata=data.frame(Age=new_age), interval=\"confidence\", level = 0.95)\nlines(new_age, conf_interval[,2], col=\"blue\", lty=2)\nlines(new_age, conf_interval[,3], col=\"blue\", lty=2)\n\npred_interval &lt;- predict(model, newdata=data.frame(Age=new_age), interval=\"prediction\", level = 0.95)\nlines(new_age, pred_interval[,2], col=\"orange\", lty=2)\nlines(new_age, pred_interval[,3], col=\"orange\", lty=2)\n</code></pre> <p>Now model the Height with the weight, with a combination of age and weight as well as age and gender allowing for a possible interaction. <pre><code>model.2 &lt;- lm(Height ~ Weight, data=class)\nsummary(model.2)\n\nmodel.3 &lt;- lm(Height ~ Age + Weight, data=class)\nsummary(model.3)\n\nmodel.4 &lt;- lm(Height ~ Age + Gender, data=class)\nsummary(model.4)\n\nmodel.5 &lt;- lm(Height ~ Age * Gender, data=class)\nsummary(model.5)\n</code></pre></p>"},{"location":"day1/#the-hellung-dataset","title":"The hellung dataset","text":"<p>Again load the data in the ISwR package called hellung and have a look at the help to understand the data. <pre><code>library(ISwR)\ndata(hellung)\n?hellung\n</code></pre> Plot the diameter of the Tetrahymena cells in relationship with the concentration of those cells. Do you have any clear evidence of what to model ?  <pre><code>plot(hellung$diameter, hellung$conc, \n     xlab=\"Diameter\", ylab=\"Concentration\")\n</code></pre></p> <p>Do a linear model between concentration and diameter, check all the assumption. Is anything violated ? <pre><code>model &lt;- lm(conc ~ diameter, data=hellung)\nsummary(model)\n\nabline(model)\n\nqqnorm(residuals(model))\nqqline(residuals(model))\nks.test(residuals(model), \"pnorm\")\n\ninfluencePlot(model, xlab=\"Hat-Values\", ylab=\"Studentized Residuals\")\n</code></pre></p> <p>We therefore need to adapt our model. In the first plot the data seemed to have a logarithmic pattern. We will try if this helps in modelling the data. <pre><code>logconc &lt;- log(hellung$conc)\nplot(hellung$diameter, logconc, \n     xlab=\"Diameter\", ylab=\"log(concentration)\")\n\nmodellog &lt;- lm(logconc ~ diameter, data=hellung)\nsummary(modellog)\n\nabline(modellog)\n</code></pre></p> <p>We also test the different assumptions. <pre><code>plot(fitted(modellog), residuals(modellog))\nqqnorm(residuals(modellog))\nqqline(residuals(modellog))\nks.test(residuals(modellog), \"pnorm\")\n</code></pre></p> <p>Now we can add glucose to the equation. What are your conclusions ? <pre><code>modellog.2 &lt;- lm(logconc ~ diameter + glucose, data=hellung)\nsummary(modellog.2)\n</code></pre></p>"},{"location":"day1/#beyond-linearity","title":"Beyond linearity","text":"<p>Again load the data this time in the SemiPar package called janka, attach the object janka to have an easier access to the variables and have a look at the help of the janka data. </p> <pre><code>library(SemiPar)\ndata(janka)\nattach(janka)\n</code></pre> <p>Plot the data using the log of the hardness. <pre><code>plot(dens,log(hardness), ylab=\"response\", xlab=\"X\", main=\"Janka data\")\n</code></pre></p>"},{"location":"day1/#linear-fit","title":"Linear fit","text":"<p>Start with a linear regression, plot the estimated fit and have a look at the residuals vs. fitted values. What do you observe ? <pre><code># fit a linear model\nfit.linear &lt;- lm( log(hardness) ~ dens )\n\n# plot the estimated linear fit\nabline(fit.linear, lwd=2, col=\"red\")\n\n# let's also look at residuals vs. fitted values\nplot(fit.linear$fitted.values, fit.linear$residuals,\n     ylim=c(-max(range(fit.linear$residuals)),max(range(fit.linear$residuals))),\n     ylab=\"residuals\", xlab=\"fitted values\")\n</code></pre></p> <p>Now you realise something seems off. Can you try to show it visually ? </p> Answer <p><pre><code># we want the error terms to be normally distributed around zero, so let's add that to the plot\nabline(a=0, b=0, col=\"blue\", lwd=2)\n\n# another way to assess the residual plot is to use a scatterplot smoother that captures the trend in residuals\n# scatter.smooth uses loess algorithm for local weighted regression\nscatter.smooth(fit.linear$fitted.values, fit.linear$residuals,\nylim=c(-max(range(fit.linear$residuals)),max(range(fit.linear$residuals))),\n           ylab=\"residuals\", xlab=\"fitted values\",\n           lpars=list(col=\"blue\", lwd=2, lty=2))\nabline(a=0, b=0, col=\"blue\", lwd=2)\nlegend(7.6,0.22,\"loess fit\",lty=2, col=\"blue\", cex=0.75)\n</code></pre> </p>"},{"location":"day1/#quadratic-fit","title":"Quadratic fit","text":"<p>The last smooth curve showed a quadratic pattern. We will try to see if we can improve the fit using the poly function and a quadratic model y = ax^2+bx+c.</p> <p>We will plot the estimated fit. To do so, we need to predict the fit at desired points on the X axis (let\u2019s call it the grid). After creating the grid, we can use predict() to estimate the fitted model on the specified grid. The arguments of the predict() function can vary depending on the object class of the fit, but R detects the appropriate predict function automatically. For example, there are predict.lm(), predict.glm(), predict.poly(), etc. The list goes on and on! In this case we feed an object of class \u201clm\u201d to predict() so you can use ?predict.lm to get more info about the arguments usage/needed.</p> <pre><code># plot raw data\nplot(dens,log(hardness), ylab=\"response\", xlab=\"X\")\n\n# fit a quadratic model\nfit.quad &lt;- lm( log(hardness) ~ poly(dens, degree=2) ) \n\n# plot the estimated linear fit\n# create a grid\ndens.range &lt;- range(dens)\ndens.grid &lt;- seq(from=dens.range[1], to=dens.range[2], length.out=100)\n\n# predict\npredict_fit.quad &lt;- predict(fit.quad, newdata=data.frame(dens=dens.grid))\nplot(dens,log(hardness), ylab=\"response\", xlab=\"X\")\nlines(dens.grid, predict_fit.quad, col=\"red\", lwd=2)\n</code></pre> <p>Seems good, but are the assumptions met ? Check the residuals vs. fitted values plot</p> <p><pre><code>plot(fit.quad$fitted.values, fit.quad$residuals, \n     ylim=c(-max(range(fit.quad$residuals)),max(range(fit.quad$residuals))), \n     ylab=\"residuals\", xlab=\"fitted values\")\nabline(a=0, b=0, col=\"blue\", lwd=2)\n</code></pre> Here some more information on the arguments required by predict(). First, you need to specify the model you\u2019re trying to predict from. Depending on the class of the fit object (e.g. lm, glm, etc.), R will then invoke a particular predict method. The second optional argument is \u201cnewdata\u201d, a data frame to let R know at which values of the predictor(s) you would want to make the predictions. Always make sure the variable names in newdata are the same as in the model. If newdata is omitted, by default predictions are made based on the data used for the fit (observed data). The accuracy or precision of our estimates can be expressed in terms of a confidence interval (CI) or a prediction interval (PI). Here is a link where these intervals are nicely explained: https://www.graphpad.com/support/faq/the-distinction-between-confidence-intervals-prediction-intervals-and-tolerance-intervals/ By setting the \u201cinterval\u201d argument to either \u201cconfidence\u201d or \u201cprediction\u201d predict() will return the requested interval along the fitted values. If you would rather do the calculations manually, you can get the standard errors on your predictions as well by setting the argument se.fit to TRUE. We will come back to intervals later. Let\u2019s move on with a LOESS smoothing of our points to assess whether the quadratic fit improved our residual plot. Looks much better, don\u2019t you agree?</p> <pre><code>scatter.smooth(fit.quad$fitted.values, fit.quad$residuals,\n               ylim=c(-max(range(fit.quad$residuals)),max(range(fit.quad$residuals))),\n               ylab=\"residuals\", xlab=\"fitted values\",\n               lpars=list(col=\"blue\", lwd=2, lty=2))\nabline(a=0, b=0, col=\"blue\", lwd=2)\nlegend(6.2,-0.1,\"loess fit\",lty=2, col=\"blue\", cex=0.75)\n</code></pre> <p>Again load the data again in the SemiPar package (so load it if not yet done so) called lidar (Light detection and ranging (LIDAR) data), attach the object lidar to have an easier access to the variables and have a look at the help of the lidar data. Start to plot the range vs logratio. </p> <pre><code>library(SemiPar)\ndata(lidar)\nattach(lidar)\n\n# plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\n</code></pre> <p>A linear and quadratic fit are clearly not appropriate for the lidar data, so let\u2019s start from polynomial degree 3. Try fitting polynomials of degree 3, 4, and 10 to lidar data</p>"},{"location":"day1/#cubic-fit","title":"Cubic fit","text":"<p>Now it should be \u201ceasy\u201d to fit a polynomial of degree 3 as well as setting a grid and plotting predictions. Not yet easy? check the answer below.</p> Answer <p><pre><code># fit a cubic model\nfit.cubic &lt;- lm( logratio ~ poly(range,3) )\n\n# set up the grid\nrange.range &lt;- range(range)\nrange.grid &lt;- seq(from=range.range[1], to=range.range[2], length.out=100)\n\n# use predict() to estimated the model at desired points on the X-axis (i.e. the grid)\npredict_fit.cubic &lt;- predict(fit.cubic, newdata=data.frame(range=range.grid))\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\nlines(range.grid, predict_fit.cubic, col=\"red\", lwd=2)\n</code></pre> </p> <p>What about the residuals ? Here also for the experts we hide the answer, for those of you that are less familiar the answer is below. </p> Answer <p><pre><code>plot(fit.cubic$fitted.values, fit.cubic$residuals, \n ylim=c(-max(range(fit.cubic$residuals)),max(range(fit.cubic$residuals))), \n ylab=\"residuals\", xlab=\"fitted values\")\nscatter.smooth(fit.cubic$fitted.values, fit.cubic$residuals,\n           ylim=c(-max(range(fit.cubic$residuals)),max(range(fit.cubic$residuals))),\n           ylab=\"residuals\", xlab=\"fitted values\",\n           lpars=list(col=\"blue\", lwd=2, lty=2))\nabline(a=0, b=0, col=\"blue\", lwd=2)\n</code></pre> </p> <p>The conclusion is that we can definitely still do better!</p>"},{"location":"day1/#polynomial-degree-4-and-10","title":"Polynomial degree 4 and 10","text":"<p>Plot the data and fit a polynomial of degree 4. Check the prediction and assumptions. </p> Answer <p><pre><code># plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\n\n# fit a quadratic model\nfit.quad &lt;- lm( logratio ~ poly(range,4) )\n\n# set up the grid\nrange.range &lt;- range(range)\nrange.grid &lt;- seq(from=range.range[1], to=range.range[2], length.out=100)\n\n# make predictions on the grid\npredict_fit.quad &lt;- predict(fit.quad, newdata=data.frame(range=range.grid))\nlines(range.grid, predict_fit.quad, col=\"red\", lwd=2)\n\n# residual plot\nplot(fit.quad$fitted.values, fit.quad$residuals, \n ylim=c(-max(range(fit.quad$residuals)),max(range(fit.quad$residuals))), \n ylab=\"residuals\", xlab=\"fitted values\")\nscatter.smooth(fit.quad$fitted.values, fit.quad$residuals,\n           ylim=c(-max(range(fit.quad$residuals)),max(range(fit.quad$residuals))),\n           ylab=\"residuals\", xlab=\"fitted values\",\n           lpars=list(col=\"blue\", lwd=2, lty=2))\nabline(a=0, b=0, col=\"blue\", lwd=2)\n</code></pre> </p> <p>What is next ? Plot the data and fit a polynomial of degree 10. Check the prediction and assumptions. </p> Answer <p><pre><code># plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\n\n# fit a polynomial degree 10\nfit.poly10 &lt;- lm( logratio ~ poly(range,10) )\n\n# set up the grid\nrange.range &lt;- range(range)\nrange.grid &lt;- seq(from=range.range[1], to=range.range[2], length.out=100)\n\n# make predictions on the grid\npredict_fit.poly10 &lt;- predict(fit.poly10,   newdata=list(range=range.grid))\nlines(range.grid, predict_fit.poly10, col=\"red\", lwd=2)\n\n# residual plot\nplot(fit.poly10$fitted.values, fit.poly10$residuals, \n ylim=c(-max(range(fit.poly10$residuals)),max(range(fit.poly10$residuals))), \n ylab=\"residuals\", xlab=\"fitted values\")\nscatter.smooth(fit.poly10$fitted.values, fit.poly10$residuals,\n           ylim=c(-max(range(fit.poly10$residuals)),max(range(fit.poly10$residuals))),\n           ylab=\"residuals\", xlab=\"fitted values\",\n           lpars=list(col=\"blue\", lwd=2, lty=2))\nabline(a=0, b=0, col=\"blue\", lwd=2)\n\n# remove the junk\nrm(fit.cubic, fit.quad, fit.poly10, predict_fit.cubic, predict_fit.quad, predict_fit.poly10, range.range, range.grid)\n</code></pre> </p> <p>Seems like the polynomial of degree 10 is fitting well the assumptions on the residuals!</p>"},{"location":"day1/#confidence-and-prediction-intervals","title":"Confidence and prediction intervals","text":"<p>Using the prediction with the polynomial of degree 3 try to calculate the confidence and prediction interval. <pre><code># plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\n\n# fit the model\nfit.cubic &lt;- lm( logratio ~ poly(range,3) )\n\n# set up the grid\nrange.range &lt;- range(range)\nrange.grid &lt;- seq(from=range.range[1], to=range.range[2], length.out=100)\n\n# use the interval argument to fetch confidence intervals\npredict_fit.cubic &lt;- predict(fit.cubic, newdata=data.frame(range=range.grid), interval=\"confidence\")\n\n# keep in mind that confidence level is by default set to 0.95, but of course can be modified via the \"level\" argument\nlines(range.grid, predict_fit.cubic[,\"fit\"], col=\"red\", lwd=2)\nlines(range.grid, predict_fit.cubic[,\"lwr\"], col=\"red\", lwd=2, lty=2)\nlines(range.grid, predict_fit.cubic[,\"upr\"], col=\"red\", lwd=2, lty=2)\n\n# alternatively we can write our own code to compute confidence intervals using the standard errors of the estimates\npredict_fit.cubic &lt;- predict(fit.cubic, newdata=list(range=range.grid), se.fit=TRUE)\n\n# plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\n\n# plot the estimated fit\nlines(range.grid, predict_fit.cubic$fit, col=\"red\", lwd=2)\n\n# compute and plot confidence bands\nlines(range.grid, predict_fit.cubic$fit + 2 * predict_fit.cubic$se.fit, col=\"red\", lwd=2, lty=2)\nlines(range.grid, predict_fit.cubic$fit - 2 * predict_fit.cubic$se.fit, col=\"red\", lwd=2, lty=2)\n\n# use the interval argument to fetch prediction intervals\npredict_fit.cubic &lt;- predict(fit.cubic, newdata=data.frame(range=range.grid), interval=\"prediction\")\n\nlines(range.grid, predict_fit.cubic[,\"lwr\"], col=\"blue\", lwd=2, lty=3)\nlines(range.grid, predict_fit.cubic[,\"upr\"], col=\"blue\", lwd=2, lty=3)\n</code></pre></p>"},{"location":"day1/#step-functions","title":"Step functions","text":"<pre><code>plot(range,logratio, ylab=\"response\", xlab=\"X\")\n\ntable(cut(range, breaks=3)) # note that you need to specify the number of breaking points\n# (390,500] (500,610] (610,720] \n# 74        74        73\n\nfit.pwsf &lt;- lm( logratio ~ cut(range,breaks=3) )\nsummary(fit.pwsf)\n\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\nrange.range &lt;- range(range)\nrange.grid &lt;- seq(from=range.range[1], to=range.range[2], length.out=100)\npredict_fit.pwsf &lt;- predict(fit.pwsf, newdata=list(range=range.grid), se.fit=TRUE)\nlines(range.grid, predict_fit.pwsf$fit, col=\"red\", lwd=2)\nlines(range.grid, predict_fit.pwsf$fit + 2 * predict_fit.pwsf$se.fit, col=\"red\", lwd=2, lty=2)\nlines(range.grid, predict_fit.pwsf$fit - 2 * predict_fit.pwsf$se.fit, col=\"red\", lwd=2, lty=2)\n</code></pre>"},{"location":"day1/#piecewise-linear-fits","title":"Piecewise linear fits","text":"<pre><code>fit.left.linear.1knot &lt;- lm( logratio ~ range, subset=(range&lt;575) )\nfit.right.linear.1knot &lt;- lm( logratio ~ range, subset=(range&gt;=575) )\n\nsummary(fit.left.linear.1knot)\nsummary(fit.right.linear.1knot)\n\n# plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\nrange.range &lt;- range(range)\nrange.grid.left &lt;- seq(from=range.range[1], to=575, length.out=50)\nrange.grid.right &lt;- seq(from=575, to=range.range[2], length.out=50)\n\n# predict the fit on the grid\n# left\npredict_fit.left.linear.1knot &lt;- predict(fit.left.linear.1knot, newdata=list(range=range.grid.left), se.fit=TRUE)\nlines(range.grid.left, predict_fit.left.linear.1knot$fit, col=\"red\", lwd=2)\nlines(range.grid.left, predict_fit.left.linear.1knot$fit + 2 * predict_fit.left.linear.1knot$se.fit, col=\"red\", lwd=2, lty=2)\nlines(range.grid.left, predict_fit.left.linear.1knot$fit - 2 * predict_fit.left.linear.1knot$se.fit, col=\"red\", lwd=2, lty=2)\n# right\npredict_fit.right.linear.1knot &lt;- predict(fit.right.linear.1knot, newdata=list(range=range.grid.right), se.fit=TRUE)\nlines(range.grid.right, predict_fit.right.linear.1knot$fit, col=\"red\", lwd=2)\nlines(range.grid.right, predict_fit.right.linear.1knot$fit + 2 * predict_fit.right.linear.1knot$se.fit, col=\"red\", lwd=2, lty=2)\nlines(range.grid.right, predict_fit.right.linear.1knot$fit - 2 * predict_fit.right.linear.1knot$se.fit, col=\"red\", lwd=2, lty=2)\n# indicate the breakpoint\nabline(v=575, col=\"blue\", lwd=2, lty=2)\n</code></pre>"},{"location":"day1/#piecewise-cubic-fits","title":"Piecewise cubic fits","text":"<pre><code>fit.left.cubic.1knot &lt;- lm( logratio ~ poly(range,3), subset=(range&lt;575) )\nfit.right.cubic.1knot &lt;- lm( logratio ~ poly(range,3), subset=(range&gt;=575) )\n\nsummary(fit.left.cubic.1knot)\nsummary(fit.right.cubic.1knot)\n\n# plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\nrange.range &lt;- range(range)\nrange.grid.left &lt;- seq(from=range.range[1], to=575, length.out=50)\nrange.grid.right &lt;- seq(from=575, to=range.range[2], length.out=50)\n\n# predict the fit on the grid\n# left\npredict_fit.left.cubic.1knot &lt;- predict(fit.left.cubic.1knot, newdata=list(range=range.grid.left), se.fit=TRUE)\nlines(range.grid.left, predict_fit.left.cubic.1knot$fit, col=\"red\", lwd=2)\nlines(range.grid.left, predict_fit.left.cubic.1knot$fit + 2 * predict_fit.left.cubic.1knot$se.fit, col=\"red\", lwd=2, lty=2)\nlines(range.grid.left, predict_fit.left.cubic.1knot$fit - 2 * predict_fit.left.cubic.1knot$se.fit, col=\"red\", lwd=2, lty=2)\n# right\npredict_fit.right.cubic.1knot &lt;- predict(fit.right.cubic.1knot, newdata=list(range=range.grid.right), se.fit=TRUE)\nlines(range.grid.right, predict_fit.right.cubic.1knot$fit, col=\"red\", lwd=2)\nlines(range.grid.right, predict_fit.right.cubic.1knot$fit + 2 * predict_fit.right.cubic.1knot$se.fit, col=\"red\", lwd=2, lty=2)\nlines(range.grid.right, predict_fit.right.cubic.1knot$fit - 2 * predict_fit.right.cubic.1knot$se.fit, col=\"red\", lwd=2, lty=2)\n# indicate the breakpoint\nabline(v=575, col=\"blue\", lwd=2, lty=2)\n</code></pre>"},{"location":"day1/#linear-splines","title":"Linear splines","text":"<pre><code>library(splines)\n\n?bs\n\nfit.ls.1knot &lt;- lm( logratio ~ bs(range, knots=575, degree=1) )\nsummary(fit.ls.1knot)\n\n# plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\nrange.range &lt;- range(range)\nrange.grid &lt;- seq(from=range.range[1], to=range.range[2], length.out=100)\n\n# predict the fit on the grid\npredict_fit.ls.1knot &lt;- predict(fit.ls.1knot, newdata=list(range=range.grid), se.fit=TRUE)\nlines(range.grid, predict_fit.ls.1knot$fit, col=\"red\", lwd=2)\nlines(range.grid, predict_fit.ls.1knot$fit + 2 * predict_fit.ls.1knot$se.fit, col=\"red\", lwd=2, lty=2)\nlines(range.grid, predict_fit.ls.1knot$fit - 2 * predict_fit.ls.1knot$se.fit, col=\"red\", lwd=2, lty=2)\nabline(v=575, col=\"blue\", lwd=2, lty=2)\n\n# repeat above with 2 internal knots at desired points\nfit.ls.2knots &lt;- lm( logratio ~ bs(range, knots=c(550,600), degree=1) )\nsummary(fit.ls.2knots)\n\n# plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\nrange.range &lt;- range(range)\nrange.grid &lt;- seq(from=range.range[1], to=range.range[2], length.out=100)\n\n# predict the fit on the grid\npredict_fit.ls.2knots &lt;- predict(fit.ls.2knots, newdata=list(range=range.grid), se.fit=TRUE)\nlines(range.grid, predict_fit.ls.2knots$fit, col=\"red\", lwd=2)\nlines(range.grid, predict_fit.ls.2knots$fit + 2 * predict_fit.ls.2knots$se.fit, col=\"red\", lwd=2, lty=2)\nlines(range.grid, predict_fit.ls.2knots$fit - 2 * predict_fit.ls.2knots$se.fit, col=\"red\", lwd=2, lty=2)\nabline(v=c(550,600), col=\"blue\", lwd=2, lty=2)\n</code></pre>"},{"location":"day1/#cubic-splines","title":"Cubic splines","text":"<pre><code># fit cubic splines with 1 internal knot\nfit.cs.1knot &lt;- lm( logratio ~ bs(range, knots=575) )\nsummary(fit.cs.1knot)\n\n# plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\nrange.range &lt;- range(range)\nrange.grid &lt;- seq(from=range.range[1], to=range.range[2], length.out=100)\n\n# predict the fit on the grid\npredict_fit.cs.1knot &lt;- predict(fit.cs.1knot, newdata=list(range=range.grid), se.fit=TRUE)\nlines(range.grid, predict_fit.cs.1knot$fit, col=\"red\", lwd=2)\nlines(range.grid, predict_fit.cs.1knot$fit + 2 * predict_fit.cs.1knot$se.fit, col=\"red\", lwd=2, lty=2)\nlines(range.grid, predict_fit.cs.1knot$fit - 2 * predict_fit.cs.1knot$se.fit, col=\"red\", lwd=2, lty=2)\nabline(v=575, col=\"blue\", lwd=2, lty=2)\n\n# fit cubic splines with 2 internal knots\nfit.cs.2knots &lt;- lm( logratio ~ bs(range, knots=c(550,600)) )\nsummary(fit.cs.2knots)\n\n# plot raw data\nplot(range,logratio, ylab=\"response\", xlab=\"X\")\nrange.range &lt;- range(range)\nrange.grid &lt;- seq(from=range.range[1], to=range.range[2], length.out=100)\n\n# predict the fit on the grid\npredict_fit.cs.2knots &lt;- predict(fit.cs.2knots, newdata=list(range=range.grid), se.fit=TRUE)\nlines(range.grid, predict_fit.cs.2knots$fit, col=\"red\", lwd=2)\nlines(range.grid, predict_fit.cs.2knots$fit + 2 * predict_fit.cs.2knots$se.fit, col=\"red\", lwd=2, lty=2)\nlines(range.grid, predict_fit.cs.2knots$fit - 2 * predict_fit.cs.2knots$se.fit, col=\"red\", lwd=2, lty=2)\nabline(v=c(550,600), col=\"blue\", lwd=2, lty=2)\n</code></pre>"},{"location":"day1/#compare-the-goodness-of-fit-of-each-model","title":"Compare the goodness of fit of each model","text":"<pre><code>mse = function(model){\n  rmse = sqrt(mean(model$residual^2))\n  round(rmse, 3)\n}\nmse_fit.ls.1knot = mse(fit.ls.1knot)\nmse_fit.ls.2knots = mse(fit.ls.2knots)\nmse_fit.cs.1knot = mse(fit.cs.1knot)\nmse_fit.cs.2knots = mse(fit.cs.2knots)\n\nmodel_name = c(\"linear splines with 1 knot\", \"linear splines with 2 knots\", \n               \"cubic splines with 1 knot\", \"cubic splines with 2 knots\")\nmses = c(mse_fit.ls.1knot, mse_fit.ls.2knots,\n         mse_fit.cs.1knot, mse_fit.cs.2knots)\nmse_table = cbind(model_name, mses)\ncolnames(mse_table) = c(\"Models\", \"RMSE\")\nknitr::kable(mse_table, caption = \"Mean squared errors for different models\", digits = 3, \"simple\")\n</code></pre>"},{"location":"day1/#smoothingnatural-splines","title":"Smoothing/natural splines","text":"<pre><code>fit.ss &lt;- smooth.spline(range, logratio)\nfit.ss\n\n# plot raw data\nplot(range, logratio, ylab=\"response\", xlab=\"X\")\nrange.range &lt;- range(range)\nrange.grid &lt;- seq(from=range.range[1], to=range.range[2], length.out=length(range))\n\n# predict the fit on the grid\n?predict.smooth.spline\npredict_fit.ss &lt;- predict(fit.ss, newdata=list(range=range.grid))\nlines(predict_fit.ss$x, predict_fit.ss$y, col=\"red\", lwd=2)\n</code></pre> <pre><code># bootstrap standard errors\n# helper functions borrowed from: \n# https://stackoverflow.com/questions/23852505/how-to-get-confidence-interval-for-smooth-spline\n\n# Helper functions\nresampler &lt;- function(data) {\n  n &lt;- nrow(data)\n  resample.rows &lt;- sample(1:n,size=n,replace=TRUE)\n  return(data[resample.rows,])\n}\n\nspline.estimator &lt;- function(data,m=100) {\n  fit &lt;- smooth.spline(x=data[,1],y=data[,2], cv=T)\n  eval.grid &lt;- seq(from=min(data[,1]),to=max(data[,1]),length.out=m)\n  return(predict(fit,x=eval.grid)$y) # We only want the predicted values\n}\n\nspline.cis &lt;- function(data,B,alpha=0.05,m=100) {\n  spline.main &lt;- spline.estimator(data,m=m)\n  spline.boots &lt;- replicate(B,spline.estimator(resampler(data),m=m))\n  cis.lower &lt;- 2*spline.main - apply(spline.boots,1,quantile,probs=1-alpha/2)\n  cis.upper &lt;- 2*spline.main - apply(spline.boots,1,quantile,probs=alpha/2)\n  return(list(main.curve=spline.main,lower.ci=cis.lower,upper.ci=cis.upper,\n              x=seq(from=min(data[,1]),to=max(data[,1]),length.out=m)))\n}\n\n# sample data\ndata &lt;- data.frame(x=range, y=logratio)\n\n# run and plot\nsp.cis &lt;- spline.cis(data, B=10000, alpha=0.05)\nplot(data[,1],data[,2], ylab=\"response\", xlab=\"X\")\nlines(x=sp.cis$x,y=sp.cis$main.curve, col=\"red\")\nlines(x=sp.cis$x,y=sp.cis$lower.ci, lty=2, lwd=2, col=\"red\")\nlines(x=sp.cis$x,y=sp.cis$upper.ci, lty=2, lwd=2, col=\"red\")\n</code></pre>"},{"location":"day2/","title":"Generalized linear models","text":"<p>In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises.</p>"},{"location":"day2/#learning-outcomes-of-the-day","title":"Learning outcomes of the day","text":"<p>After having completed this chapter you will be able to:</p> <ul> <li>Understand why linear models are not enough and how to spot it (Warm up)</li> <li>Understand logistic regression with its residuals (Warm up)</li> <li>Generalised linear models (Poisson for Warm up 2)</li> <li>Understand proportion datasets, like in epidemiological studies (Baby food, Michelin Food)</li> <li>Predict values for a new dataset (Michelin Food)</li> <li>Interaction terms in proportion datasets (Moth death)</li> <li>Understand the effect of different link functions (Beetle)</li> <li>Understand diagnostic tools and confidence intervals (Pima)</li> <li>Understand what an offset is (Lung cancer)</li> </ul> <p>Slides of lectures:</p> <p>Download slides</p>"},{"location":"day2/#warm-up","title":"Warm up","text":"<p>The data records the birth weight of 1174 babies along with information on the mother and the pregnancy. Load and explore the dataset babies, called babies.RData in your exercise folder. <pre><code>load(\"exercises/babies.RData\")\nattach(babies)\n</code></pre></p> <p>Perform a graphical exploration of the data <pre><code>summary(babies)\npairs(babies)\n</code></pre></p> <p>Which factor can explain prematurity?  Can we use a linear model? If so, try to make predictions.</p> Answer <p><pre><code>model1 &lt;- lm(as.numeric(as.numeric(levels(prem))[prem]) ~ bwt)\nsummary(model1)\n\nplot(bwt, as.numeric(as.numeric(levels(prem))[prem]), ylab=\"premature\", xlab=\"birth weight\", main=\"Babies\",\nxlim=c(0,200), ylim=c(-0.2,1.2))\nabline(model1, col=\"red\", lwd=2)\n\nnew_bwt = 170\npredict.model1 &lt;- predict.lm(model1, newdata=data.frame(bwt=new_bwt))\npoints(new_bwt, predict.model1, col=\"blue\")\n</code></pre> </p> <p>Fit a logistic regression to find parameters explaining the probability of prematurity ?  What is the effect of birth weight on the probability of prematurity ?  What about parity ?</p> Answer <pre><code>model2 &lt;- glm(prem ~ bwt, family=binomial)\nsummary(model2)\n\nmodel3 &lt;- glm(prem ~ bwt+parity, family=binomial)\nsummary(model3)\n\nmodel4 &lt;- glm(prem ~ bwt*smoke+parity, family=binomial)\nsummary(model4)\n</code></pre> <p>Check the deviance residuals using the residualPlot function in the car library <pre><code>library(car)\nresidualPlot(model2, type = \"deviance\")\nresidualPlot(model2, type = \"response\")\nresidualPlot(model2, type = \"pearson\")\n</code></pre></p> <p>Construct the quantile residuals using the qresiduals function in the statmod library Analyze the deviance Look for potential influencial and outlying observations</p> Hint <p>Use the function acf()</p> Answer <p><pre><code>library(statmod)\nmodel2.residuals &lt;- qresiduals(model2)\nqqnorm(qnorm(model2.residuals))\nqqline(qnorm(model2.residuals), col=\"red\")\n\nmodel.null &lt;- glm(prem ~ 1, family = binomial)\nsummary(model.null)\nanova(model.null, model2, test = \"Chisq\")\n\ninfluencePlot(model2)\nacf(model2.residuals)\n</code></pre> </p>"},{"location":"day2/#challenge-baby-food","title":"Challenge: baby food","text":"<pre><code>library(faraway)\ndata(babyfood)\n</code></pre> <p>Explore the data</p> <p><pre><code>summary(babyfood)\nboxplot(disease ~ food, babyfood)\nboxplot(disease ~ sex, babyfood)\nboxplot((disease/(disease + nondisease)) ~ food, babyfood)\nboxplot((disease/(disease + nondisease)) ~ sex, babyfood)\n</code></pre> </p> <p>Fit a logistic regression to explain the probability of disease by sex and food.</p> Answer <pre><code>mdl &lt;- glm(cbind(disease, nondisease) ~ sex + food, family = binomial, babyfood)\nsummary(mdl)\n</code></pre>"},{"location":"day2/#warm-up-2","title":"Warm up 2","text":"<p>Explore the dataset gala in library faraway. Remove the variable \u201cendemics\u201d which we will not use here. <pre><code>library(faraway)\ndata(gala)\ngala &lt;- gala[,-2]\n\nsummary(gala)\n</code></pre></p> <p>Study the relationship between the number of plant species and several geographical variables of interest.</p> <p><pre><code>pairs(gala)\n</code></pre> </p> <p>Fit a poisson model to the galapagos data. Which variables are significant ?  Check the deviance of the model</p> <p><pre><code>poisson.glm &lt;- glm(Species ~ ., data=gala, family=poisson)\nsummary(poisson.glm)\nresidualPlots(poisson.glm)\n</code></pre> </p>"},{"location":"day2/#exercise-1-michelin-food","title":"Exercise 1: Michelin food","text":"<p>Here, we will use a data set containing food ratings for a number of restaurants,  as well as information about whether or not they are included in the Michelin guide.  The data set (called MichelinFood.txt) can be downloaded from the webpage of the book  \u201cA Modern Approach to Regression with R\u201d by Simon J Sheather. Download the file and import it into R or load it from the exercises folder.</p> <pre><code>michelin &lt;- read.delim(\"exercises/MichelinFood.txt\", header=TRUE, sep=\"\\t\", as.is=TRUE)\nmichelin\n</code></pre> <p>The Food column represents the ranking of the food.  The columns InMichelin and NotInMichelin contain the number of restaurants with  the given food ranking that are/are not listed in the Michelin guide, respectively.  The mi column contains the total number of examined restaurants with the given food ranking.  Finally, the proportion column contains the fraction of examined restaurants with  the given food ranking that were included in the Michelin guide.</p> <ol> <li>Start by graphically exploring the data</li> </ol> <pre><code>plot(michelin$Food, michelin$proportion)\n</code></pre> <ol> <li>Fit a GLM using a binomial model for the response, using the food ranking as the predictor.</li> </ol> <pre><code>glm.mich &lt;- glm(cbind(InMichelin, NotInMichelin) ~ Food, family = binomial(logit),\n                data = michelin)\n</code></pre> <ol> <li>Predict the probabilities for a number of potential food rankings xnew, and plot a smooth function</li> </ol> <pre><code>xnew &lt;- data.frame(Food = seq(from = 14, to = 30, length.out = 50))\npred.prop &lt;- predict(glm.mich, newdata = xnew, type = \"response\")\nplot(michelin$Food, michelin$proportion)\nlines(xnew$Food, pred.prop, col = \"blue\", lwd = 2)\n</code></pre> <ol> <li>Check the model by looking at the residual deviance, other residuals and especially the quantile residuals</li> </ol> Answer <p><pre><code>require(car)\nresidualPlot(glm.mich, type = \"deviance\")\nresidualPlot(glm.mich, type = \"response\")\nresidualPlot(glm.mich, type = \"pearson\")\nlibrary(statmod)\nqres &lt;- qresiduals(glm.mich)\nqqnorm(qres)\nqqline(qres)\nacf(qres)\n</code></pre> </p> <p> </p> <p> </p> <p> </p> <p> </p> <ol> <li>Check the model for potential influencial observations.</li> </ol> Answer <p><pre><code>influencePlot(glm.mich)\n</code></pre> </p>"},{"location":"day2/#exercise-2-moth-death","title":"Exercise 2: moth death","text":"<p>The next data set comes from Venables and Ripley (page 190) and encodes the number of moths that died after exposure to different doses of trans-cypermethrin. 20 male and 20 female moths were exposed to each dose, and the number of deaths in each group was recorded. We generate a data frame containing the observed values. Since the doses are powers of two, we use log2(dose) as the predictor rather than the actual dose.</p> <pre><code>moth &lt;- data.frame(sex = rep(c(\"male\", \"female\"), each = 6),\n                   dose = log2(rep(c(1, 2, 4, 8, 16, 32), 2)),\n                   numdead = c(1, 4, 9, 13, 18, 20, 0, 2, 6, 10, 12, 16))\nmoth$numalive &lt;- 20 - moth$numdead\n</code></pre> <ol> <li>Fit a GLM using the sex and dose as predictors. </li> </ol> <p>Do we need to include an interaction term in the model ?</p> Answer <pre><code>glm.moth.1 &lt;- glm(cbind(numalive, numdead) ~ sex + dose, data = moth, family = binomial)\nsummary(glm.moth.1)\nglm.moth.2 &lt;- glm(cbind(numalive, numdead) ~ sex * dose, data = moth, family = binomial)\nsummary(glm.moth.2)\n</code></pre> <ol> <li>Does the model fit well ? Perform an analysis of deviance</li> </ol> <pre><code>glm.null &lt;- glm(cbind(numalive, numdead) ~ 1, data = moth, family = binomial)\nsummary(glm.null)\n</code></pre> <p>If a pair of models is nested (i.e. the smaller model is a special case of the larger one) then we can test H0 : smaller model is true versus H1 : larger model is true by doing likelihood ratio testing, and comparing the difference in deviance to a chi2 distribution with degrees of freedom = df for smaller model - df for larger model <pre><code>anova(glm.null, glm.moth.1, test = \"Chisq\")\n</code></pre> 3. Predict the probabilities for different doses and include a smooth line in the plots</p> <p><pre><code>xnew &lt;- data.frame(sex = rep(c(\"male\", \"female\"), each = 30), \n                   dose = rep(seq(from = 0, to = 5, length.out = 30), 2))\npred.prop &lt;- predict(glm.moth.1, newdata = xnew, type = \"response\")\nmoth$proportion &lt;- moth$numalive/(moth$numdead + moth$numalive)\ncolor &lt;- moth$sex\ncolor[color == \"male\"] &lt;- \"blue\"\ncolor[color == \"female\"] &lt;- \"red\"\nplot(moth$proportion ~ moth$dose, col = as.character(color))\nlines(xnew$dose[which(xnew$sex == \"male\")], pred.prop[which(xnew$sex == \"male\")],\n      col = \"blue\", lwd = 2)\nlines(xnew$dose[which(xnew$sex == \"female\")], pred.prop[which(xnew$sex == \"female\")],\n      col = \"red\", lwd = 2)\n</code></pre> </p>"},{"location":"day2/#exercise-3-beetle","title":"Exercise 3: beetle","text":"<p>The third example of a binomial response considers an experiment where beetles were exposed to carbon disulphide at various concentrations, and the number of beetles who died within five hours were recorded. The data set is studied in the book by Dobson (2002), and comes originally from Bliss (1935). <pre><code>beetles &lt;- data.frame(dose = c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.861, 1.8839), \n                      dead = c(6, 13, 18, 28, 52, 53, 61, 60), \n                      alive = c(51, 47, 44, 28, 11, 6, 1, 0))\n</code></pre></p> <ol> <li>Fit a logistic regression to the data using dose as a predictor</li> </ol> <pre><code>glm.beetles &lt;- glm(cbind(alive, dead) ~ dose, beetles, family = \"binomial\")\nsummary(glm.beetles)\n</code></pre> <ol> <li>Fit another logistic regression using the log-log link. Compare the two fits.</li> </ol> <pre><code>glm.beetles.log &lt;- glm(cbind(alive, dead) ~ dose, beetles, family = binomial(cloglog))\nsummary(glm.beetles.log)\n</code></pre> <ol> <li>Compare the predictions of each model</li> </ol> <p><pre><code>new_beetle &lt;- data.frame(dose = seq(from = 1.5, to = 1.9, length.out = 100))\nplot(predict(glm.beetles, new_beetle, type = \"response\"),ylab=\"response\", type = \"l\", col = \"blue\")\nlines(predict(glm.beetles.log, new_beetle, type = \"response\"), col = \"red\")\n</code></pre> </p>"},{"location":"day2/#exercise-4-pima","title":"Exercise 4: Pima","text":"<p>The national institute of Diabetes and digestive and kidney diseases conducted a study on 768 adult female Pima Indians living near Phoenix. The purpose of the study was to investigate the factors related to diabetes. pregnant: number of times pregnant glucose: plasma glucose concentration at 2 hours in an oral glucose tolerance test diastolic: diastolic blood pressure (mm Hg) triceps: triceps skin fold thickness (mm) insulin: 2-Hour serum insulin (mu U/ml) bmi: body mass index (weight in kg/(height in metres squared)) diabetes: diabetes pedigree function (scores likelihood of diabetes based on family history) age: age (years) test: test whether the patient shows signs of diabetes (0: negative, 1: positive) <pre><code>library(faraway)\ndata(\"pima\")\n</code></pre></p> <ol> <li>Perform a simple graphical and numerical inspection of the dataset.   Can you find any obvious irregularities in the data ?  If you do, use the appropriate strategy to correct the problems</li> </ol> <p><pre><code>str(pima)\nsummary(pima)\n</code></pre> <pre><code>pima$glucose[which(pima$glucose == 0)] &lt;- NA\npima$diastolic[which(pima$diastolic == 0)] &lt;- NA\npima$triceps[which(pima$triceps == 0)] &lt;- NA\npima$insulin[which(pima$insulin == 0)] &lt;- NA\npima$bmi[pima$bmi == 0] &lt;- NA\n\npima$test &lt;- factor(pima$test)\nlevels(pima$test) &lt;- c(\"negative\", \"positive\")\ntable(pima$test)\n\nboxplot(pima$diastolic ~ pima$test)\nboxplot(pima$pregnant ~ pima$test)\nboxplot(pima$glucose ~ pima$test)\nboxplot(pima$triceps ~ pima$test)\nboxplot(pima$insulin ~ pima$test)\nboxplot(pima$bmi ~ pima$test)\nboxplot(pima$diabetes ~ pima$test)\nboxplot(pima$age ~ pima$test)\n</code></pre></p> <ol> <li>Fit a model with the result of the diabetes test as the response and all the  other variables as predictors. Can you tell whether this model fits the data ?</li> </ol> <pre><code>glm.pima.full &lt;- glm(test ~ ., pima, family = binomial)\nsummary(glm.pima.full)\n\nlibrary(car)\nresidualPlots(glm.pima.full)\n\nlibrary(statmod)\nqqnorm(qresiduals(glm.pima.full))\nqqline(qresiduals(glm.pima.full))\nqres &lt;- qresiduals(glm.pima.full)\nplot(qres ~ predict(glm.pima.full, type = \"link\"))\nacf(qres)\n</code></pre> <p>The fit is quite good. The residuals are good and the uniform residuals pass all the checks. There are many non-significant variables so we can remove them to have a better fit.</p> <ol> <li>On the basis of the previous result, try to fit another model</li> </ol> <pre><code>glm.pima &lt;- glm(test ~ glucose + bmi + diabetes, pima, family = binomial)\nsummary(glm.pima)\n\nresidualPlots(glm.pima)\nqqnorm(qresiduals(glm.pima))\nqqline(qresiduals(glm.pima))\nqres &lt;- qresiduals(glm.pima)\nplot(qres ~ predict(glm.pima, type = \"link\"))\nacf(qres)\n\ninfluenceIndexPlot(glm.pima, vars = c(\"Cook\", \"Studentized\", \"hat\"))\n</code></pre> <ol> <li>Using the previous model, predict the outcome for a woman with the following predictor values:</li> </ol> <pre><code>new_pima &lt;- data.frame(pregnant = 1, glucose = 99, diastolic = 64, triceps = 22,\n                       insulin = 76, bmi = 27, diabetes = 0.25, age = 25)\npred_prob &lt;- predict(glm.pima, newdata = new_pima, type = \"response\", se = TRUE)\n\npred_prob$fit \n\npred_logit &lt;- predict(glm.pima, newdata = new_pima, se = TRUE)\n\nilogit(pred_logit$fit) \nilogit(pred_logit$fit - 1.96 * pred_logit$se.fit)\nilogit(pred_logit$fit + 1.96 * pred_logit$se.fit)\n</code></pre>"},{"location":"day2/#exercise-5-lung-cancer","title":"Exercise 5: lung cancer","text":"<p>Here we will consider a data set from the ISwR package, which contains the number of lung cancer cases recorded in different age categories in four different Danish cities. The cases column contains the number of lung cancer cases for each city and age category.</p> <pre><code>library(ISwR)\ndata(eba1977)\neba1977\n</code></pre> <ol> <li>Model this count using the city and age category as predictors.</li> </ol> <p>Fit a Poisson GLM to the data. Is the fit appropriate ?</p> <pre><code>glm.cancer &lt;- glm(cases ~ city + age, data = eba1977, family = poisson)\nsummary(glm.cancer)\n</code></pre> <ol> <li> <p>In the previous model, we are not considering the number of potential cases in each group  (i.e. the population size). Modify the model by using an offset which takes the population size into account. <pre><code>glm.cancer.off &lt;- glm(cases ~ offset(log(pop)) + city + age, data = eba1977,\n                      family = poisson)\nsummary(glm.cancer.off)\n</code></pre></p> </li> <li> <p>Fit a binomial model to the data by considering success as being lung cancer cases and failures as being: populationsize - number of cases.</p> </li> </ol> <pre><code>success &lt;- eba1977$cases\nfailures &lt;- eba1977$pop - eba1977$cases\nglm.cancer.bin &lt;- glm(cbind(success, failures) ~ city + age, family = \"binomial\",\n                      data = eba1977)\nsummary(glm.cancer.bin)\n</code></pre> <ol> <li>Compare with the Poisson model.</li> </ol> <p>We see that the results are very close to those obtained with the Poisson model with offset. This is because the number of cases is generally very low compared to the population size, in other words, the population size is almost infinite compared to the number of cases. In this situation, the Poisson distribution is closely related to the binomial distribution.</p>"},{"location":"day3/","title":"Mixed-effects linear models and longitudinal data analysis","text":"<p>In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises.</p> <p>After having completed this chapter you will be able to:</p> <ul> <li>Plot individual linear models or LOESS fits on data (Tolerance data)</li> <li>Understand Mixed Effect Models </li> <li>Understand Fixed and Random effects on categorical data (Corn)</li> <li>Understand longitudinal data analysis (Tolerance data)</li> <li>Understand comparisons of models (Tolerance data)</li> <li>Biological interpretation of model comparisons (BtheB data)</li> <li>Integrating B-Spline Basis matrix for Polynomial Splines and random effects (Bone data set)</li> <li>Interaction term and Random effects (Brain Data)</li> </ul> <p>Slides of lectures:</p> <p>Download slides</p> <pre><code>library(lattice)\nlibrary(nlme)\nlibrary(splines)\n</code></pre>"},{"location":"day3/#tolerance-data-set","title":"Tolerance data set","text":"<pre><code># load the \"tolerance\" data set: \"tolerance.RData\"\nload(\"exercises/tolerance.RData\")\n\nstr(tolerance_untidy)\nstr(tolerance_tidy)\n</code></pre>"},{"location":"day3/#perform-a-graphical-exploration-of-the-data","title":"Perform a graphical exploration of the data","text":"<pre><code># scatterplots of raw data\nxyplot(tolerance ~ age | as.factor(id), ylim=c(0,4), data=tolerance_tidy, as.table=F)\n</code></pre>"},{"location":"day3/#analysis-of-individual-change-over-time","title":"Analysis of individual change over time","text":""},{"location":"day3/#non-parametric-smoothing-spline-fit","title":"Non-parametric smoothing spline fit","text":"<p>We first fit a smoothing spline between the points, this is done using the function panel.spline(). <pre><code>xyplot(tolerance ~ age | as.factor(id), ylim=c(0,4), data=tolerance_tidy, \n       prepanel = function(x,y) prepanel.spline(x,y), \n       xlab = \"age\", ylab = \"tolerance\", \n       panel = function(x,y){ \n         panel.xyplot(x,y) \n         panel.spline(x,y)}\n)\n</code></pre></p>"},{"location":"day3/#nonparametric-loess-fit","title":"Nonparametric loess fit","text":"<p>Try fitting a LOESS function on the xy panel. </p> Hint <p>Try the help function ?prepanel.spline() that you have seen previously for smoothing splines to understand what to change. Is it the only function you need to change ?</p> Answer <pre><code>xyplot(tolerance ~ age | as.factor(id), ylim=c(0,4), data=tolerance_tidy,\n   prepanel = function(x,y) prepanel.loess(x,y, family=\"gaussian\"),\n   xlab = \"age\", ylab = \"tolerance\",\n   panel = function(x,y){\n     panel.xyplot(x,y)\n     panel.loess(x,y, family=\"gaussian\")}\n)\n</code></pre>"},{"location":"day3/#parametriclinear-fit","title":"Parametric/linear fit","text":"<p>Try now a linear fit. Which function do you need to change</p> Answer <pre><code>xyplot(tolerance ~ age | as.factor(id), ylim=c(0,4), data=tolerance_tidy,\n   prepanel = function(x,y) prepanel.lmline(x,y),\n   xlab = \"age\", ylab = \"tolerance\",\n   panel = function(x,y){\n     panel.xyplot(x,y)\n     panel.lmline(x,y)}\n  )\n</code></pre>"},{"location":"day3/#individual-linear-fits","title":"Individual linear fits","text":"<p>Extract summary from individual linear fits. <pre><code>lm.summary &lt;- by(tolerance_tidy, tolerance_tidy$id, function(x) summary(lm(tolerance ~ time, data=x)))\nlm.summary[1]\nlm.summary[[1]]$coefficients\n\n# fetch intercepts\nall.intercept &lt;- sapply(lm.summary, function(x) x$coefficients[1,1])\n\n# fetch slopes\nall.slope &lt;- sapply(lm.summary, function(x) x$coefficients[2,1])\n\n# fetch residual variances, i.e. (Residual standard error)^2\nall.resVar &lt;- sapply(lm.summary, function(x) (x$sigma)^2)\n\n# fetch R-squared statistic\nall.r2 &lt;- sapply(lm.summary, function(x) x$r.squared)\n\n# combine them in one matrix\nmy.summary &lt;- rbind(all.intercept, all.slope, all.resVar, all.r2)\nmy.summary\n\n# remove the junk\nrm(all.intercept, all.slope, all.resVar, all.r2)\n</code></pre></p>"},{"location":"day3/#analysis-of-inter-individual-differences","title":"Analysis of inter-individual differences","text":""},{"location":"day3/#average-of-the-curves-nonparametric","title":"Average of the curves (nonparametric)","text":"<p>We will proceed by making a plot with all the smooth splines calculated for all the individual. We then calculate averages of values calculated on a grid. This points will then be used to again calculate a smoothing spline.  <pre><code># start with an empty plot\nplot(1, type=\"n\", xlab=\"age\", ylab=\"tolerance\", xlim=c(11,15), ylim=c(0,4), main=\"nonparametric\")\n\n# i) discretize time on a grid\nt &lt;- seq(11,15,length.out=100)\n\n# ii) estimate individual trajectories\nindiv &lt;- unique(tolerance_tidy$id)\n\n# create matrix to store estimates on the grid\nest.nonpara &lt;- matrix(NA, nrow=16, ncol=100)\n\n# loop on individuals to plot individual curves and extract estimates on the grid\nfor (i in 1:length(indiv)) {\n  temp.data &lt;- subset(tolerance_tidy, subset=(id==indiv[i]))\n  age &lt;- temp.data$age\n  tolerance &lt;- temp.data$tolerance\n  fit &lt;- smooth.spline(age, tolerance)\n  est &lt;- predict(fit, data.frame(age=t))\n  # plot the estimate\n  lines(t(est$x),t(est$y), col=\"grey\")\n  # store the estimate\n  est.nonpara[i,] &lt;- t(est$y)\n}\n\n# average individual estimates for each point on the grid\navg.est &lt;- apply(est.nonpara, MARGIN=2, mean)\n\n# apply same smoothing algorithm to averages\nfit &lt;- smooth.spline(t, avg.est)\n\n# overlay the curve of the averages\nlines(t, fit$y, lwd=2)\n\n# assign ids to rownames\nrownames(est.nonpara) &lt;- indiv\nest.nonpara\n\n# remove the junk\nrm(t,indiv,i,temp.data,age,tolerance,fit,est,avg.est)\n</code></pre></p>"},{"location":"day3/#average-of-the-curves-parametric","title":"Average of the curves (parametric)","text":"<p>In the parametric form, we will predict values on a grid for all the samples, then calculate averages. <pre><code># start with an empty plot\nplot(1, type=\"n\", xlab=\"age\", ylab=\"tolerance\", xlim=c(11,15), ylim=c(0,4), main=\"parametric\")\n\n# i) discretize time on a grid\nt &lt;- seq(11,15,length.out=100)\n\n# centering time predictor is optional but doing so improves the interpretability of the intercept (i.e. the intercept will reflect baseline exposure at age=11)\nt.cent &lt;- seq(0,4,length.out=100) \n\n# ii) estimate individual trajectories\nindiv &lt;- unique(tolerance_tidy$id)\n\n# matrix to store estimates on the grid\nest.para &lt;- matrix(NA, nrow=16, ncol=100)\n\n# loop on individuals to plot individual curves and extract estimates on the grid\nfor (i in 1:length(indiv)) {\n  temp.data &lt;- subset(tolerance_tidy, subset=(id==indiv[i]))\n  age &lt;- temp.data$age\n  age.cent &lt;- temp.data$age - 11\n  tolerance &lt;- temp.data$tolerance\n  fit &lt;- lm(tolerance ~ age.cent)\n  est &lt;- predict(fit, data.frame(age.cent=t.cent), type=\"response\")\n  # plot the estimate\n  abline( lm( tolerance ~ age), col=\"grey\")\n  # store the estimate\n  est.para[i,] &lt;- est\n}\n\n# average individual estimates for each point on the grid\navg.est &lt;- apply(est.para, MARGIN=2, mean)\n\n# apply same smoothing algorithm to averages\nabline(lm( avg.est ~ t), lwd=2)\n\n# assign ids to rownames\nrownames(est.para) &lt;- indiv\nest.para\n\n# remove the junk\nrm(t,t.cent,indiv,i,temp.data,age,age.cent,tolerance,fit,est,avg.est)\n</code></pre></p>"},{"location":"day3/#intercepts-and-slopes-from-linear-fit","title":"Intercepts and slopes from linear fit","text":"<p>Fetch the intercepts and slopes from the linear fit <pre><code># all.intercepts\nmean(my.summary[\"all.intercept\",]) # 1.35775\nsqrt( var(my.summary[\"all.intercept\",]) ) # 0.2977792\n\n# all.slopes\nmean(my.summary[\"all.slope\",]) # 0.1308125\nsqrt( var(my.summary[\"all.slope\",]) ) # 0.172296\n\n# bivariate correlation\ncor(my.summary[\"all.intercept\",], my.summary[\"all.slope\",]) # -0.4481135\n</code></pre></p>"},{"location":"day3/#stratify-based-on-covariates","title":"Stratify based on covariates","text":"<p>We can stratify the calculated curves based on covariates. We can associate p-values of the estimated parameters, answering questions such as is there any major difference in the calculated slopes in Men vs Women ? This enables to obtain p-value on inter-individual changes.  We first start with the covariate Gender:  <pre><code>table(tolerance_untidy$male) # 9 x females and 7 x males\n\n# discretize time on a grid\nt &lt;- seq(11,15,length.out=100)\n\n# figure with 2 panels\npar(mfrow=c(1,2))\n\n# plot individual males\nest.para_males &lt;- est.para[rownames(est.para) %in% tolerance_untidy$id[tolerance_untidy$male==1], ]\nplot(1, type=\"n\", xlab=\"age\", ylab=\"tolerance\", xlim=c(11,15), ylim=c(0,4), main=\"males\")\napply(est.para_males, MARGIN=1, function(x,t) {lines(t,x, col=\"gray\")}, t=t)\navg.est &lt;- apply(est.para_males, MARGIN=2, mean)\nabline(lm( avg.est ~ t), lwd=2)\n\n# plot individual females\nest.para_females &lt;- est.para[rownames(est.para) %in% tolerance_untidy$id[tolerance_untidy$male==0], ]\nplot(1, type=\"n\", xlab=\"age\", ylab=\"tolerance\", xlim=c(11,15), ylim=c(0,4), main=\"females\")\napply(est.para_females, MARGIN=1, function(x,t) {lines(t,x, col=\"gray\")}, t=t)\navg.est &lt;- apply(est.para_females, MARGIN=2, mean)\nabline(lm( avg.est ~ t), lwd=2)\n\n# remove the junk\nrm(est.para_males, est.para_females, t, avg.est)\n</code></pre></p> <p>Then the covariate Exposure: <pre><code>summary(tolerance_untidy$exposure)\n\n# exposure is a continuous time-invariant predictor, and thus can be categorized for visualization\nmedian.exposure &lt;- median(tolerance_untidy$exposure)\n\n# discretize time on a grid\nt &lt;- seq(11,15,length.out=100)\n\n# figure with 2 panels\npar(mfrow=c(1,2))\n\n# plot individuals with high-exposure\nest.para_highExposure &lt;- est.para[rownames(est.para) %in% tolerance_untidy$id[tolerance_untidy$exposure &gt; median.exposure], ]\nplot(1, type=\"n\", xlab=\"age\", ylab=\"tolerance\", xlim=c(11,15), ylim=c(0,4), main=\"high-exposure\")\napply(est.para_highExposure, MARGIN=1, function(x,t) {lines(t,x, col=\"gray\")}, t=t)\navg.est &lt;- apply(est.para_highExposure, MARGIN=2, mean)\nabline(lm( avg.est ~ t), lwd=2)\n\n# plot individuals with low-exposure\nest.para_lowExposure &lt;- est.para[rownames(est.para) %in% tolerance_untidy$id[tolerance_untidy$exposure &lt;= median.exposure], ]\nplot(1, type=\"n\", xlab=\"age\", ylab=\"tolerance\", xlim=c(11,15), ylim=c(0,4), main=\"low-exposure\")\napply(est.para_lowExposure, MARGIN=1, function(x,t) {lines(t,x, col=\"gray\")}, t=t)\navg.est &lt;- apply(est.para_lowExposure, MARGIN=2, mean)\nabline(lm( avg.est ~ t), lwd=2)\n\n# remove the junk\nrm(est.para_highExposure, est.para_lowExposure, t, avg.est)\nrm(median.exposure)\n</code></pre></p>"},{"location":"day3/#corn-data","title":"Corn Data","text":"<p>We work with the dataframe: ant111b in the DAAG package. It is an agricultural experiment on the Caribbean island of Antigua. Corn yield measurements were taken on 4 parcels at 8 sites. We need to discover how to model the harvest weight, and understand if there are significant changes in the sites and parcels, or other covariates in this dataset.  <pre><code>library(DAAG)\nlibrary(lattice) \nlibrary(lme4)\nlibrary(WWGbook)\n</code></pre></p>"},{"location":"day3/#data-exploration-of-harvwt","title":"Data Exploration of harvwt","text":"<pre><code>data(ant111b)\n\nstr(ant111b)\nsummary(ant111b) \n\ndotplot(reorder(site, harvwt) ~ harvwt, ant111b, xlab = \"Harvest weight of corn\",\n        ylab = \"Site\", pch = 19, aspect = 0.32, type = c(\"p\", \"a\"))\n</code></pre> <p>The line joins the means of the harvest weight of the individual sites. The sites have been reordered by increasing mean harvwt</p>"},{"location":"day3/#data-modelling-with-fixed-and-random-effects","title":"Data modelling with fixed and random effects","text":"<p>Model the harvwt by the sites and compare to a null model. Then, add a random effect.  <pre><code>summary( lm( ant111b$harvwt ~ ant111b$site ) )\nanova( lm( ant111b$harvwt ~ ant111b$site ) )\n\nmodel.1 &lt;- lm( ant111b$harvwt ~ ant111b$site )\nmodel.null &lt;- lm( ant111b$harvwt ~ 1 )\nanova(model.null, model.1)\n\nmean(ant111b$harvwt)\nmean(ant111b[ant111b$site == \"DBAN\",]$harvwt)\nmean(ant111b[ant111b$site == \"LFAN\",]$harvwt)\nmean(ant111b[ant111b$site == \"NSAN\",]$harvwt)\nmean(ant111b[ant111b$site == \"ORAN\",]$harvwt)\nmean(ant111b[ant111b$site == \"OVAN\",]$harvwt)\nmean(ant111b[ant111b$site == \"TEAN\",]$harvwt)\nmean(ant111b[ant111b$site == \"WEAN\",]$harvwt)\nmean(ant111b[ant111b$site == \"WLAN\",]$harvwt)\n\nant111b.lmer &lt;- lmer(harvwt ~ 1 + (1 | site), data=ant111b)\nant111b.lmer\n</code></pre></p> <p>Our model has one fixed effect parameter (the first 1): the mean harvest weight and one random effect term (1|site): the variation across sites. There are two sources of random variation: one for site and one for parcel within site. The estimated variance components are: site = 1.5392^2 = 2.369 residual = 0.762 = 0.577</p> <pre><code>mean(ant111b$harvwt)\nsqrt(var(ant111b$harvwt))\nfixef(ant111b.lmer)\n</code></pre> <p>The numbers provided by ranef aren\u2019t estimates of the random effects They are called BLUPs (Best Linear Unbiased Predictors) of the random effects. <pre><code>ranef(ant111b.lmer)\nfitted(ant111b.lmer)\n\nmeans &lt;- with(ant111b, sapply(split(harvwt, site), mean))\nsiteFit &lt;- with(ant111b, sapply(split(fitted(ant111b.lmer), site), mean))\nprint(data.frame(mean = means, fitted = siteFit))\n</code></pre></p> <p>The fitted values are not just the sample means. They are shrinkage estimates that are between the grand (overall) mean and the individual sample means <pre><code># site  mean    fitted      site    ranef   \n# DBAN  4.885   4.851         DBAN  0.559     0.061\n# LFAN  4.208   4.212         LFAN  -0.079  0.061\n# NSAN  2.090   2.217         NSAN  -2.075  0.061\n# ORAN  6.915   6.764         ORAN  2.473     0.061\n# OVAN  4.833   4.801         OVAN  0.510     0.061\n# TEAN  3.036   3.108         TEAN  -1.183  0.061\n# WEAN  5.526   5.455         WEAN  1.164     0.061\n# WLAN  2.841   2.925         WLAN  -1.367  0.061\n# var     2.512 2.232         var     2.232 \n# stdev 1.585   1.494         stdev 1.494   \n</code></pre> This can be summarized with the following dotplot. <pre><code>dotplot(ranef(ant111b.lmer, condVar = TRUE), strip = FALSE)[[1]] \n</code></pre></p> <p>Now, we will do the same type of modeling but this time with the ears variable as the outcome.</p>"},{"location":"day3/#1-data-exploration-of-ear","title":"1. Data exploration of ear","text":"<p>Make a dotplot of the number of ears by site, sorting by mean ears as follows: <pre><code>dotplot(reorder(site, ears) ~ ears, ant111b, xlab = \"Number of ears of corn\", \n        ylab = \"Site\", pch = 19, aspect = 0.32, type = c(\"p\", \"a\"))\n</code></pre></p> <p>Comment on your plot - do any effects seem to contribute to the variation in ears ? </p>"},{"location":"day3/#2-fit-a-random-effects-model","title":"2. Fit a random effects model","text":"<p><pre><code>ears.lmer &lt;- lmer(ears ~ 1 + (1 | site), data=ant111b)\nsummary(ears.lmer)\n</code></pre> There are two sources of random variation, one for site and one for parcel within site (residual), each with an estimated variance (and SD).</p> <p>Find the grand mean. <pre><code>mean(ant111b$ears)\nfixef(ears.lmer)\n</code></pre></p> <p>Make a table showing the sample mean and fitted value for each site. Note that the fitted values are not just the sample means, but are between the grand mean and individual group sample means. <pre><code>means &lt;- with(ant111b, sapply(split(ears, site), mean))\nsiteFit &lt;- with(ant111b, sapply(split(fitted(ears.lmer), site), mean))\nprint(data.frame(mean = means, fitted = siteFit))\n</code></pre></p> <p>Give the estimated variance for each source of variation, site and residual.</p> <pre><code>variance.site =  6.760^2 = 45.696\nvariance.residual = 3.980^2 = 15.839 \n</code></pre> <p>Which source of variation is larger ? What proportion of variation is due to differences between sites ? Make a caterpillar plot for the random effects. Does the plot support your conclusion about the source of variation ? Which site(s) are most \u2018unusual\u2019?</p> <pre><code>dotplot(ranef(ears.lmer, condVar = TRUE), strip = FALSE)[[1]] \n</code></pre>"},{"location":"day3/#3-model-assumptions","title":"3. Model assumptions","text":"<p>It is also a good idea to check the model assumptions with a few diagnostic plots. There should not be any apparent pattern in the residuals. You can check this by making a plot of residuals versus fitted values: <pre><code>plot(fitted(ears.lmer), residuals(ears.lmer), main=\"residual plot\", pch=19)\nabline(h=0, lty=2)\n</code></pre></p> <p>The residuals should also be normally distributed. You can check this by making a normal quantile-quantile (QQ) plot. If the points fall along a straight line, the distribution is approximately normal. <pre><code>qqnorm(resid(ears.lmer))\nqqline(resid(ears.lmer)) \nshapiro.test(resid(ears.lmer))\n</code></pre> What do you conclude ? </p>"},{"location":"day3/#tolerance-data-set2","title":"Tolerance data set2","text":"<p>We take again a look at the tolerance dataset and will have now a new look on it with mixed effect modelling.</p> <pre><code>library(lattice)\nlibrary(nlme)\nlibrary(splines)\n</code></pre>"},{"location":"day3/#multi-level-mixed-effects-modeling","title":"multi-level / mixed-effects modeling","text":"<p>Let\u2019s begin by assessing the need for a multi-level model First, we will fit a baseline model (only including an intercept) using ML Next, we will fit another model that allows intercepts to vary between clusters (i.e. a random intercept model) finally we compare the two models to see if the fit has improved as a result of allowing intercepts to vary</p>"},{"location":"day3/#fit-the-1st-model","title":"Fit the 1st model","text":"<p>Simplest model, also called null model. <pre><code>fit.01 &lt;- gls(tolerance ~ 1, data=tolerance_tidy, method=\"ML\")\nsummary(fit.01)\n\n# plot fit.01\nplot(tolerance_tidy$age, tolerance_tidy$tolerance, ylim=c(0,4), ylab=\"tolerance\", xlab=\"age\")\nfit.01$coefficients\nabline(h=1.619375, col=\"red\", lwd=2)\n</code></pre></p>"},{"location":"day3/#fit-the-2nd-model","title":"Fit the 2nd model","text":"<p>Now we put a random effect that is linked to the ids of the kids. This assumes that there is no change true time in the answer to the tolerance in kids, however kids ID matter, i.e. some kids will start higher and some lower and will stay high respectively low in their tolerance to deviant behaviour. <pre><code>fit.02 &lt;- lme(tolerance ~ 1, random = (~ 1 | id), data=tolerance_tidy, method=\"ML\")\nsummary(fit.02)\nfit.02$coefficients\n\n# plot fit.02 for patient \"978\" and compare with fit.01\nplot(tolerance_tidy$age, tolerance_tidy$tolerance, ylim=c(0,4), ylab=\"tolerance\", xlab=\"age\")\npoints(tolerance_tidy$age[tolerance_tidy$id==\"978\"], tolerance_tidy$tolerance[tolerance_tidy$id==\"978\"], col=\"blue\", pch=16)\nfit.02$coefficients\nabline(h = fit.02$coefficients$fixed, col=\"red\", lwd=2)\nfit.02$coefficients$fixed + unlist(fit.02$coefficients$random)[12]\nabline(h = fit.02$coefficients$fixed + unlist(fit.02$coefficients$random)[12], col=\"blue\", lwd=2)\n\n# plot fit.02 for all individual\nplot(tolerance_tidy$age, tolerance_tidy$tolerance, ylim=c(0,4), ylab=\"tolerance\", xlab=\"age\")\nabline(h = fit.02$coefficients$fixed + unlist(fit.02$coefficients$random), col=\"blue\", lwd=2)\n</code></pre></p> <p>Compare the two using AIC, BIC, and likelihood-ratio(LR) <pre><code>anova(fit.01,fit.02)\n</code></pre> Keeping in mind that the assumptions of the LR test is that: i) models were fit using ML ii) model are nested both assumption were met and p-val&lt;0.05; therefore we can conclude that allowing for random intercepts significantly improved the fit</p>"},{"location":"day3/#fit-the-3rd-model","title":"Fit the 3rd model","text":"<p>What if instead of random intercepts, we had allowed for random slopes? We have no reason to believe that individuals should share a baseline value (i.e. fixed intercept), but let\u2019s try it anyways for the sake of completeness. This model will assume that there is a fixed intercept, therefore all the fitted lines start at the same height. But we say that time influences the results of the tolerance. How would you model it?</p> Answer <pre><code>fit.03 &lt;- gls(tolerance ~ time, data=tolerance_tidy, method=\"ML\") # using centered age (i.e.     time) for increased interpretability\nsummary(fit.03)\n\n# plot fit.03\nplot(tolerance_tidy$age, tolerance_tidy$tolerance, ylim=c(0,4), ylab=\"tolerance\",     xlab=\"age\")\nfit.03$coefficients\nabline( gls(tolerance ~ age, data=tolerance_tidy, method=\"ML\"), col=\"red\", lwd=2)\n</code></pre>"},{"location":"day3/#fit-the-4th-model","title":"Fit the 4th model","text":"<p>What if the tolerance can be explained by time, but that the changes through time are dependant on the kid. But we expect the intercept to be the same for all individuals. </p> Answer <pre><code>fit.04 &lt;- lme(tolerance ~ time, random = (~ -1 + time | id), data=tolerance_tidy,     method=\"ML\")\nsummary(fit.04)\nfit.04$coefficients\n\n# plot fit.04 for patient \"978\" and compare with fit.03\nplot(tolerance_tidy$age, tolerance_tidy$tolerance, ylim=c(0,4), ylab=\"tolerance\", xlab=\"age\")\npoints(tolerance_tidy$age[tolerance_tidy$id==\"978\"], tolerance_tidy$tolerance[tolerance_tidy$id==\"978\"], col=\"blue\", pch=16)\nabline(lm(tolerance ~ age, data=tolerance_tidy), col=\"red\", lwd=2)\npredict.fit.04 &lt;- predict(fit.04, newdata=data.frame(time=seq(0,4,length.out=100), id=\"978\"))\nlines(seq(11,15,length.out=100), predict.fit.04, col=\"blue\", lwd=2)\n\n# plot fit.04 for all individuals\nplot(tolerance_tidy$age, tolerance_tidy$tolerance, ylim=c(0,4), ylab=\"tolerance\", xlab=\"age\")\nid &lt;- as.character(unique(tolerance_untidy$id))\nfor (i in 1:length(id)) {\n predict.fit.04 &lt;- predict(fit.04, newdata=data.frame(time=seq(0,4,length.out=100), id=id[i]))\n lines(seq(11,15,length.out=100), predict.fit.04, col=\"blue\", lwd=1)\n}\n</code></pre> <p>compare the two using AIC, BIC, and LR</p> <pre><code>anova(fit.03,fit.04)\n</code></pre>"},{"location":"day3/#fit-the-5th-model","title":"Fit the 5th model","text":"<p>What if instead we had allowed for both random intercepts and random slopes? This means kids do not all start at the same tolerance level, tolerance changes through time but also each kids way of changing true time is significantly different. </p> Answer <pre><code>fit.05 &lt;- lme(tolerance ~ time, random = (~ time | id), data=tolerance_tidy, method=\"ML\")\nsummary(fit.05)\n\n\n# extract both fixed and random parameters\nfit.05$coefficients\ncoef(fit.05) # only fixed parameters\nranef(fit.05) # only random parameters\n</code></pre> <p>compare the two using likelihood-ratio(LR) <pre><code>anova(fit.03,fit.05)\n# Based on what we saw above, can you plot these fitted models? (i.e. fit.03 and fit.05)\n</code></pre></p>"},{"location":"day3/#fit-the-6th-model","title":"Fit the 6th model","text":"<p>Now let\u2019s bring in additional covariates. </p> <p>Starting with adding gender, are boys and girls any different in how they tolerate deviant behaviour ?  <pre><code>tolerance_tidy$male &lt;- factor(tolerance_tidy$male, levels=c(0,1))\nfit.06 &lt;- lme(tolerance ~ male + time, random = (~ time | id), data=tolerance_tidy, method=\"ML\")\nsummary(fit.06)\nanova(fit.03,fit.06)\n</code></pre></p>"},{"location":"day3/#fit-the-7th-model","title":"Fit the 7th model","text":"<p>adding exposure. This is the starting measure each kid has given. <pre><code>fit.07 &lt;- lme(tolerance ~ male + exposure + time, random = (~ time | id), data=tolerance_tidy, method=\"ML\")\nsummary(fit.07)\nanova(fit.06,fit.07)\n</code></pre></p>"},{"location":"day3/#fit-the-8th-model","title":"Fit the 8th model","text":"<p>adding interaction between male and exposure, is the exposure of boys and exposure of girls having a different impact on tolerance (this would be the case for instance if one suspects that girls that rate themselves higher at start have then a very different, for instance more steap curve then boys that rate themselves with a high exposure value).</p> Answer <pre><code>fit.08 &lt;- lme(tolerance ~ male * exposure + time, random = (~ time | id), data=tolerance_tidy, method=\"ML\")\nsummary(fit.08)\nanova(fit.07,fit.08)\n</code></pre>"},{"location":"day3/#fit-the-9th-model","title":"Fit the 9th model","text":"<p>adding interaction between male and time.</p> <pre><code>fit.09 &lt;- lme(tolerance ~ exposure + male * time, random = (~ time | id), data=tolerance_tidy, method=\"ML\")\nsummary(fit.09)\nanova(fit.07,fit.09) # this agrees with our observation from exploratory analysis\n</code></pre>"},{"location":"day3/#fit-the-10th-model","title":"Fit the 10th model","text":"<p>adding interaction between exposure and time <pre><code>fit.10 &lt;- lme(tolerance ~ male + exposure * time, random = (~ time | id), data=tolerance_tidy, method=\"ML\")\nsummary(fit.10)\nanova(fit.07,fit.10)\n</code></pre> This agrees with our observation from exploratory analysis Based on above, we will choose fit.07 as our model.</p>"},{"location":"day3/#btheb-data-set","title":"BtheB data set","text":"<p>Load the needed packages <pre><code>library(lattice)\nlibrary(nlme)\nlibrary(splines)\n</code></pre></p> <p>Load and hava a look at the \u201cBtheB_tidy\u201d data set: \u201cBtheB_tidy.RData\u201d <pre><code>load(\"exercises/BtheB_tidy.RData\")\n\n# examine the data \nstr(BtheB.tidy)\n</code></pre></p> <p>Store \u201cpre\u201d bdi values separately as baseline <pre><code>temp.pre &lt;- subset( BtheB.tidy, subset=(timepoint==\"pre\") )\ntemp.pre &lt;- temp.pre[,c(5,6)]\nBtheB.tidy &lt;- subset( BtheB.tidy, subset=(timepoint!=\"pre\") )\ntemp &lt;- BtheB.tidy$indiv\ntemp2 &lt;- c()\nfor (i in 1:length(temp)) {\n  temp2[i] &lt;- temp.pre$bdi[temp.pre$indiv==temp[i]]\n}\nBtheB.tidy &lt;- cbind.data.frame(BtheB.tidy, pre.bdi=temp2)\nrm(temp.pre,temp,temp2,i)\n</code></pre></p> <p>Let\u2019s convert timepoints to numerics <pre><code>temp &lt;- as.character(BtheB.tidy$timepoint)\ntemp &lt;- replace(temp, temp==\"2m\", 2)\ntemp &lt;- replace(temp, temp==\"4m\", 4)\ntemp &lt;- replace(temp, temp==\"6m\", 6)\ntemp &lt;- replace(temp, temp==\"8m\", 8)\nBtheB.tidy$timepoint &lt;- as.numeric(temp)\nstr(BtheB.tidy)\nrm(temp)\n</code></pre></p>"},{"location":"day3/#exploratory-analysis","title":"Exploratory analysis","text":"<pre><code># raw data\nxyplot(bdi ~ timepoint | indiv, data=BtheB.tidy, as.table=F,\n       xlab = \"time\", ylab = \"bdi\")\n</code></pre>"},{"location":"day3/#model-fittingselection","title":"Model fitting/selection","text":"<pre><code>fit.01 &lt;- gls(bdi ~ timepoint, data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nfit.02 &lt;- lme(bdi ~ timepoint, random = (~ 1 | indiv), data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nanova(fit.01,fit.02)\n</code></pre> <p>What is the conclusion ? </p> Answer <p>Including random intercepts improves the goodness of fit.</p> <p><pre><code>fit.03 &lt;- lme(bdi ~ timepoint, random = (~ timepoint | indiv), data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nanova(fit.02,fit.03)\n</code></pre> And here ?</p> Answer <p>Including random slopes does not improve the goodness of fit Based on the result above, we will choose the simpler random intercepts model </p> <p>Note</p> <p>In lme by default na.action is set to na.fail, hence you\u2019ll get an error if NA values are present.By setting na.action=na.omit, we throw away rows with NAs in them. Keep in mind that we are not throwing away subjects (cases) who happen to have a missing value, just those time points that have missing response</p> <p>Let\u2019s bring in the covariate drug. <pre><code>fit.04 &lt;- lme(bdi ~ drug + timepoint, random = (~ 1 | indiv), data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nsummary(fit.04)\nanova(fit.02,fit.04)\n</code></pre></p> <p>How about length ? <pre><code>fit.05 &lt;- lme(bdi ~ length + timepoint, random = (~ 1 | indiv), data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nsummary(fit.05)\nanova(fit.02,fit.05)\n</code></pre></p> <p>How about treatment ? <pre><code>fit.06 &lt;- lme(bdi ~ treatment + timepoint, random = (~ 1 | indiv), data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nsummary(fit.06)\nanova(fit.02,fit.06)\n</code></pre></p> <p>How about baseline ? <pre><code>fit.07 &lt;- lme(bdi ~ pre.bdi + timepoint, random = (~ 1 | indiv), data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nsummary(fit.07)\nanova(fit.02,fit.07)\n</code></pre></p> <p>Is there an interaction between baseline and temporal pattern ? <pre><code>fit.08 &lt;- lme(bdi ~ pre.bdi * timepoint, random = (~ 1 | indiv), data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nsummary(fit.08)\nanova(fit.07,fit.08)\n</code></pre> What if we had included all covariates from the beginning ? <pre><code>fit.09 &lt;- gls(bdi ~ pre.bdi + drug + length + treatment + timepoint, data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nsummary(fit.09)\n</code></pre> <pre><code>fit.10 &lt;- lme(bdi ~ pre.bdi + drug + length + treatment + timepoint, random = (~ 1 | indiv), data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nsummary(fit.10)\n</code></pre> Compare the fits <pre><code>anova(fit.09,fit.10)\n</code></pre> <pre><code>fit.11 &lt;- lme(bdi ~ pre.bdi + drug + length + treatment + timepoint, random = (~ timepoint | indiv), data=BtheB.tidy, method=\"ML\", na.action=na.omit)\nsummary(fit.11)\n</code></pre> Compare the fits <pre><code>anova(fit.10,fit.11)\n</code></pre></p> <p>let\u2019s look at summary of fit.10 one more time <pre><code>summary(fit.10)\n</code></pre> While baseline and time both significantly affect bdi, there is no evidence for a treatment effect  </p>"},{"location":"day3/#bone-data-set","title":"Bone data set","text":"<p>Load packages <pre><code>library(lattice)\nlibrary(nlme)\nlibrary(splines)\n</code></pre> Relative spinal bone mineral density (spnbmd) measurements on 261 North American adolescents. Each value is the difference in spnbmd between two consecutive visits, divided by the average. The age is the average of the age over the two visits. load and examine the \u201cbone\u201d data set: \u201cbone.RData\u201d</p> <pre><code>load(\"exercises/bone.RData\")\n\n# examine the data \nstr(bone)\n</code></pre> <p>convert idnum to factor <pre><code>bone$idnum &lt;- factor(bone$idnum)\nstr(bone)\n</code></pre></p>"},{"location":"day3/#exploratory-analysis_1","title":"Exploratory analysis","text":"<pre><code># raw data\nxyplot(spnbmd ~ age | idnum, data=bone, subset=(idnum %in% sample(bone$idnum, size=50, replace=F)), \n       as.table=F, xlab = \"age\", ylab = \"spnbmd\")\n</code></pre>"},{"location":"day3/#parametriclinear-fit_1","title":"Parametric/linear fit","text":"<pre><code>xyplot(spnbmd ~ age | idnum, data=bone, subset=(idnum %in% sample(bone$idnum, size=50, replace=F)),\n       prepanel = function(x,y) prepanel.lmline(x,y),\n       xlab = \"age\", ylab = \"spnbmd\",\n       panel = function(x,y) {\n         panel.xyplot(x,y)\n         panel.lmline(x,y) }\n)\n</code></pre>"},{"location":"day3/#compare-the-trends-for-male-and-females","title":"Compare the trends for male and females","text":"<p>We will ignore the repeated measures <pre><code>plot( bone$age, bone$spnbmd, xlab=\"age\", ylab=\"spnbmd\")\nbone.spline.male &lt;- with(subset(bone,gender==\"male\"), smooth.spline(age, spnbmd))\nbone.spline.female &lt;- with(subset(bone, gender==\"female\"), smooth.spline(age, spnbmd))\nlines(bone.spline.male, col=\"blue\", lwd=3)\nlines(bone.spline.female, col=\"red2\", lwd=3)\nlegend(20,0.20, legend=c(\"male\", \"Female\"), col=c(\"blue\", \"red2\"), lwd=2)\n</code></pre></p>"},{"location":"day3/#using-cubic-splines","title":"Using cubic splines","text":"<pre><code>0.5*(bone.spline.female$df + bone.spline.male$df) # 6.6\nplot(spnbmd~age,data=bone)\nfit.00 &lt;- lm(spnbmd ~ gender * bs(age, df=6), data=bone) # df=6 corresponds to 3 internal knots\npredict.male &lt;- predict(fit.00, newdata=data.frame(age=seq(10,25,by=.5), gender=\"male\"))\npredict.female &lt;- predict(fit.00, newdata=data.frame(age=seq(10,25,by=.5), gender=\"female\"))\nlines(seq(10,25,by=.5), predict.male, col=\"blue\", lwd=3)\nlines(seq(10,25,by=.5), predict.female, col=\"red\", lwd=3)\n</code></pre>"},{"location":"day3/#model-fittingselection_1","title":"Model fitting/selection","text":"<pre><code>fit.01 &lt;- gls(spnbmd ~ gender * bs(age, df=6), data=bone, method=\"ML\")\nsummary(fit.01)\n\nfit.02 &lt;- lme(spnbmd ~ gender * bs(age, df=6), random=(~1 | idnum), data=bone, method=\"ML\")\nsummary(fit.02)\n\nanova(fit.01,fit.02)\n\n# testing if males and females show different trends\nfit.02 &lt;- lme(spnbmd ~ gender * bs(age, df=6), random=(~1 | idnum), data=bone, method=\"ML\")\nfit.03 &lt;- lme(spnbmd ~ gender + bs(age, df=6), random=(~1 | idnum), data=bone, method=\"ML\")\nanova(fit.02,fit.03)\n</code></pre> <p>Therefore we conclude that change in relative spinal bone mineral density versus age is different between males and females.</p>"},{"location":"day3/#rat-brain-data","title":"Rat Brain Data","text":"<p><pre><code>library(DAAG)\nlibrary(lattice) \nlibrary(lme4)\nlibrary(WWGbook)\n</code></pre> The rat brain data is called rat.brain in the WWGbook package. The aim of the experiment was to examine nucleotide activation (guanine nucleotide bonding) in six different brain nuclei (i.e., brain regions) among five adult male rats. A data frame with 30 observations on the following 4 variables. animal: Unique identifier for each rat treatment: Level of drug treatment (1 = Basal, 2 = Carbachol) region: Brain nucleus (1 = BST, 2 = LS, 3 = VDB) activate: Nucleotide activation (the dependent variable)</p>"},{"location":"day3/#1-exploration-of-the-data","title":"1. Exploration of the data","text":"<pre><code>attach(rat.brain)\nstr(rat.brain)\nsummary(rat.brain)\n</code></pre> <p>In order to use treatment and region correctly in the model, they will each need to be coded as a factor (what type of variables are they now ?):</p> <pre><code>region.f &lt;- region\nregion.f[region == 1] &lt;- 1\nregion.f[region == 2] &lt;- 2\nregion.f[region == 3] &lt;- 0\nregion.f &lt;- factor(region.f)\nlevels(region.f) &lt;- c(\"VST\", \"BST\", \"LS\")\n\ntreat &lt;- factor(treatment)\nlevels(treat) &lt;- c(\"Basal\",\"Carbachol\")\n\nrat.brain &lt;- data.frame(rat.brain, region.f, treat)\n\nstr(rat.brain)\nsummary(rat.brain)\n</code></pre> <p>First try to get some idea what the data look like through graphical exploration. Here are a few different representations of the data. Try them all out - which do you think is most revealing ? <pre><code>dotplot(reorder(animal, activate) ~ activate, rat.brain, \n        groups = region.f, ylab = \"Animal\", xlab = \"Activate\", pch=19, \n        type = c(\"p\", \"a\"), auto.key=list(columns=3, lines=TRUE)) \n</code></pre></p> <p>Here we have plotted results for each rat (ordered by increasing mean(activate), but this includes both treatment measurements for each rat. Let\u2019s look at each rat/treatment combination separately: <pre><code>rat.brain$rt &lt;- with(rat.brain, treat:factor(animal))\n\ndotplot(reorder(rt, activate) ~ activate, rat.brain, groups = region.f, \n        ylab = \"Animal\", xlab = \"Activate\", pch=19, \n        type = c(\"p\", \"a\"), auto.key=list(columns=3, lines=TRUE))\n</code></pre></p> <p>Each rat separately:</p> <pre><code>xyplot(activate ~ treat | animal, rat.brain, aspect = \"xy\", layout = c(5,1), \n       groups=region.f, pch=19, type=c(\"p\", \"l\", \"g\"), \n       index.cond = function(x,y) coef(lm(y~x))[1], xlab = \"Treatment\", \n       ylab=\"Activate\", auto.key=list(space=\"top\",lines=TRUE,columns=3))\n</code></pre> <p>Separated by treatment group: <pre><code>xyplot(activate ~ region.f|treat, rat.brain, groups = animal, pch=19, \n       ylim=c(0,800), xlab=\"Region\", ylab=\"Activate\", \n       type = c(\"p\",\"a\"), auto.key = list(space=\"top\"))\n</code></pre></p> <p>Does the treatment appear to have an effect ? Why do you say that ?  Does the effect (if any) appear to be the same in each region ? Do there appear to be rat-specific effects ? </p>"},{"location":"day3/#2-model-fitting","title":"2. Model fitting","text":"<p>We will start with fitting a model including all fixed effects (main effects and interactions for the treatment and region variables - make sure to use the factor versions) and a random effect for animal. As above, you can use extractor functions to view some of the model components. <pre><code>rat.brain.lmer1 &lt;- lmer(activate ~ region.f*treat + (1|animal), REML=TRUE, data = rat.brain)\nsummary(rat.brain.lmer1)\n</code></pre> Make sure that you know how to interpret the coefficients (the interpretation will be determined by the coding). </p>"},{"location":"day3/#3-add-random-effects","title":"3. Add random effects","text":"<p>From the plot above, we saw that between-animal variation was greater for the carbachol treatment than for the basal treatment. To accommodate this difference in variation, we can add a random animal-specific effect of treatment to the model. The effect of treatment is fixed in our original model, therefore constant across all animals. The additional random effect associated with treatment that we include in the new model allows the implied marginal variance of observations for the carbachol treatment to differ from that for the basal treatment. We can also think of the new model as having two random intercepts per rat, one for the carbachol treatment and an additional one for the basal treatment. <pre><code>rat.brain.lmer2 &lt;- lmer(activate ~ region.f*treat + (treat |animal), REML=TRUE, data = rat.brain)\nsummary(rat.brain.lmer2)\n</code></pre> What happens to the estimated fixed effects coefficients? What about their standard errors?</p>"},{"location":"day3/#4-compare-using-lr","title":"4. Compare using LR","text":"<p>We can compare the models using a likelihood ratio (LR) test, carried out with the anova function. The anova method for mer objects carries out a ML (not REML) LR test, even if the model has been fit by REML. The results are not identical for the two methods, but in this case the conclusions are the same.</p> <pre><code>anova(rat.brain.lmer1, rat.brain.lmer2)\n</code></pre>"},{"location":"day3/#5-model-assumptions","title":"5. Model assumptions","text":"<p>As above, we check some diagnostics for the final model.</p> <p>Residual plot: <pre><code>fit &lt;- fitted(rat.brain.lmer2)\nres &lt;- resid(rat.brain.lmer2)\nplotres.fit &lt;- data.frame(rat.brain, fit, res)\nxyplot(res ~ fit, data=plotres.fit, groups=treat, pch=19, xlab=\"Predicted value\",\n       ylab=\"Residual\", abline=0, auto.key=list(space=\"top\", columns=2))\n</code></pre> <pre><code># QQ normal plot:\nqqnorm(resid(rat.brain.lmer2))\nqqline(resid(rat.brain.lmer2))\n</code></pre> What do you conclude ?</p>"},{"location":"day4/","title":"Generalized additive models","text":"<p>In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises.</p> <p>After having completed this chapter you will be able to:</p> <ul> <li>Understand how Generalized additive models work and why they are useful</li> </ul> <p>Exercise 1: Mid-Atlantic Wage Data</p> <p>Wage and other data for a group of 3000 male workers in the Mid-Atlantic region.</p> <p>First we set for this exercise the libraries that we will need.</p> <pre><code>library(akima)\nlibrary(gam)\nlibrary(ISLR)\nlibrary(splines)\n</code></pre> <p>We will now load the Mid-Atlantic Wage dataset which is part of the ISLR package, which is called Wage.</p> <p>First have a look at the available variables by checking the help of that package. Once the ISLR package is loaded it attached to your environment some variable that are ready to use as year, age and wage for instance which are part of the Wage data.</p> <pre><code>?Wage\n\n# explore the data\nstr(Wage)\n\n# see for example the head of the year variable which is available\nhead(year)\n</code></pre> <p>Now the goal is to build a predictive model for wage based on year, age, marital status and other variables. We will do the exercise in 7 parts, which we separate in different exercises.</p>"},{"location":"day4/#step1-from-linear-to-degree-5-polynomial-regression","title":"Step1: From linear to degree-5 polynomial regression","text":"<p>The goal is to fit models ranging from linear to a degree-5 polynomial and seek to determine the simplest model which is sufficient to explain the relationship between wage and age.</p> <p>First, we perform a linear regression, and we have a look at the summary of the fit. How do you write this ?</p> Hint <p>Use anova() to perform an F-test to compare nested models.</p> Answer <pre><code>fit1 &lt;- lm(wage ~ age, data=Wage)\nsummary(fit1)\n</code></pre> <p>Now we use the poly function for polynomial regression. Which one looks best ? Compare the different fits!</p> <pre><code>fit2 &lt;- lm(wage ~ poly(age,2), data=Wage)\nsummary(fit2)\nanova(fit1, fit2)\nfit3 &lt;- lm(wage ~ poly(age,3), data=Wage)\nsummary(fit3)\nanova(fit2, fit3)\nfit4 &lt;- lm(wage ~ poly(age,4), data=Wage)\nsummary(fit4)\nanova(fit3, fit4)\nfit5 &lt;- lm(wage ~ poly(age,5), data=Wage)\nsummary(fit5)\nanova(fit4, fit5)\n</code></pre> Answer <p>The p-value comparing the linear Model 1 to the quadratic Model 2 is essentially zero (&lt;10^15), indicating that a linear fit is not sufficient. Similarly the p-value comparing the quadratic Model 2 to the cubic Model 3 is very low (0.0017), so the quadratic fit is also insufficient. The p-value comparing the cubic and degree-4 polynomials, Model 3 and Model 4, is approximately 5% while the degree-5 polynomial Model 5 seems unnecessary because its p-value is 0.37. Hence, either a cubic or a quartic polynomial appear to provide a reasonable fit to the data, but lower- or higher-order models are not justified.</p>"},{"location":"day4/#step2-predict-whether-an-individual-earns-more-than-250000-per-year","title":"Step2: Predict whether an individual earns more than $250\u2018000 per year","text":"Hint <p>First create the appropriate response vector using I(), and then apply the glm() function using family=\u201dbinomial\u201d in order to fit a polynomial logistic regression model.</p> <pre><code>fit.glm.4 &lt;- glm(I(wage&gt;250) ~ poly(age,4), data=Wage, family=binomial)\nsummary(fit.glm.4)\n\nagelims = range(age)\nage.grid = seq(from=agelims[1],to=agelims[2])\npred.fit.glm.4 = predict(fit.glm.4, newdata=list(age=age.grid), se=T)\n\nproba.fit.glm.4 = exp(pred.fit.glm.4$fit)/(1+exp(pred.fit.glm.4$fit))\nse.bands.logit = cbind(pred.fit.glm.4$fit + 2*pred.fit.glm.4$se.fit, \n                       pred.fit.glm.4$fit - 2*pred.fit.glm.4$se.fit)\nse.bands = exp(se.bands.logit)/(1+exp(se.bands.logit))\n\nplot(age, I(wage &gt; 250), xlim=agelims, type =\"n\", ylim=c(0,1))\npoints(jitter(age), I(wage&gt;250), cex=.5, pch=\"|\", col =\"darkgrey\")\nlines(age.grid, proba.fit.glm.4, lwd=2, col=\"blue\")\nmatlines(age.grid, se.bands, lwd =1, col=\"blue\", lty =2)\n</code></pre>"},{"location":"day4/#step3-step-functions-to-model-relationship-between-wage-and-age","title":"Step3 : Step functions to model relationship between wage and age","text":"Hint <p>Use cut() to fit step functions.</p> <pre><code>table(cut(age,4))\nfit.step = lm(wage ~ cut(age,4), data=Wage)\nsummary(fit.step)\nplot(fit.step)\n</code></pre>"},{"location":"day4/#step4-linear-and-cubic-splines","title":"Step4: Linear and cubic splines","text":"<p>We proceed in 3 steps here.</p> <p>i) Fit wage to age using linear splines with internal knots at 25th, 50th and 75th percentiles of age. ii) Repeat with a cubic spline. iii) Test if using cubic splines improved the goodness of fit.</p> Hint <p>Use bs() to fit splines</p> <pre><code>quantile(age, probs=0.25)\nquantile(age, probs=0.5)\nquantile(age, probs=0.75)\nfit.linearsplines = lm(wage ~ bs(age, knots=c(33.75,42,51)), data=Wage)\npred.fit.linearsplines = predict(fit.linearsplines, newdata=list(age=age.grid), se=T)\nplot(age, wage, col=\"gray\")\nlines(age.grid, pred.fit.linearsplines$fit, lwd=2)\nlines(age.grid, pred.fit.linearsplines$fit+2*pred.fit.linearsplines$se, lty=\"dashed\")\nlines(age.grid, pred.fit.linearsplines$fit-2*pred.fit.linearsplines$se, lty=\"dashed\")\n</code></pre>"},{"location":"day4/#step5-smoothing-splines","title":"Step5 : Smoothing splines","text":"<p>Start with fitting wage to age using smoothing splines.Then assess the effect of varying \u201cdf\u201d on the smooth.  In this exercise, try different df for different smoothing. df controls the \u201ccomplexity\u201d of the model employed. What do you observe ?</p> <pre><code># (the model only gets more complex, but the general shape won't change).\nfit.smooth.spline.5 = smooth.spline(age, wage, df=5)\nfit.smooth.spline.10 = smooth.spline(age, wage, df=10)\nfit.smooth.spline.15 = smooth.spline(age, wage, df=15)\nfit.smooth.spline.20 = smooth.spline(age, wage, df=20)\n# cross-validation\nfit.smooth.spline.cv = smooth.spline(age, wage, cv=TRUE)\n\nplot(age, wage, col=\"gray\")\nlines(fit.smooth.spline.5, col=\"red\",lty=1)\nlines(fit.smooth.spline.10, col=\"red\",lty=2)\nlines(fit.smooth.spline.15, col=\"red\",lty=3)\nlines(fit.smooth.spline.20, col=\"red\",lty=4)\nlines(fit.smooth.spline.cv, col=\"blue\",lty=1)\nlegend(\"topright\", legend=c(\"5 DF\",\"10 DF\",\"15 DF\",\"20 DF\",\"6.8 DF\"), \n       col=c(\"red\",\"red\",\"red\",\"red\",\"blue\"), lty=c(1,2,3,4,1), cex=.8)\n</code></pre> Answer\u201d <p>A substantial difference can be found when going from 2 to 10, but very little change will take place when going from 10 to 50 </p>"},{"location":"day4/#step6-local-regressions","title":"Step6: Local regressions","text":"<p>Fit wage to age using a local regression (loess function) with default parameters What does the parameter \u201cspan\u201d refer to in the loess function? How does increasing the \u201cspan\u201d affect the fit?</p> <pre><code>fit.local = loess(wage ~ age, span =.2, data=Wage)\nfit.local.2 = loess(wage ~ age, span =.5, data=Wage)\nplot(age, wage, xlim=agelims, cex=.5, col=\"darkgrey\")\ntitle(\"Local Regression\")\nlines(age.grid, predict(fit.local,data.frame(age=age.grid)), col =\"red \",lwd=2)\nlines(age.grid, predict(fit.local.2,data.frame(age=age.grid)), col =\" blue\",lwd=2)\nlegend(\"topright\",legend=c(\"Span=0.2\",\"Span=0.5\"), col=c(\"red\", \"blue\"), lty =1, lwd =2, cex =.8)\n</code></pre>"},{"location":"day4/#step7-general-additive-model","title":"Step7 : General Additive Model","text":"<p>Load the library \u201cgam\u201d and try to look at the help of the gam function. Fit a GAM to predict wage using smoothing splines of year and age, treating education as a qualitative predictor Repeat using a GAM with a loess smoother. Try to plot the fitted gam objects.</p> <pre><code>gam.s = gam(wage ~ s(year,4)+s(age,5)+education, data=Wage)\nplot(gam.s)\ngam.lo.1 = gam(wage ~ lo(year,span=0.5)+lo(age,span=0.5)+education, data=Wage)\nplot(gam.lo.1)\n</code></pre>"},{"location":"day4/#step8-anova-tests","title":"Step8: ANOVA tests","text":"<p>Determine which of these three models is the best: i) a GAM that excludes year (M1), ii) a GAM that uses a linear function of year (M2), iii) or a GAM that uses a spline function of year (M3). iv) Make prediction on the training set (original data) using M2 from above.</p> <pre><code>gam.m1 = gam(wage ~ s(age,5)+education, data=Wage)\ngam.m2 = gam(wage ~ year+s(age,5)+education, data=Wage)\ngam.m3 = gam(wage ~ s(year,4)+s(age,5)+education, data=Wage)\nanova(gam.m1,gam.m2,gam.m3,test=\"F\")\n\npred.gam.m2 = predict(gam.m2,newdata=Wage)\n</code></pre>"},{"location":"day4/#step9-gams-with-interaction","title":"Step9: GAMs with interaction","text":"<p>Use <code>r lo()</code> function to allow for interaction between age and year in the GAM, treating education like before. We can plot the resulting two-dimensional surface using the akima package (akima::plot).</p> <pre><code>gam.lo.2 = gam(wage ~ lo(year,age,span=0.5)+education, data=Wage)\nplot(gam.lo.2)\n</code></pre>"},{"location":"day4/#step10-logistic-regression-gams","title":"Step10: Logistic regression GAMs","text":"<p>Try to fit a logistic regression GAM, handling year with a linear function, age with a smoothing spline, and education with dummy variables like before. Try removing the \u201c&lt;HS\u201d category. Use the <code>r plot()</code> function to visualize the logistic regression GAMs.</p> <pre><code>gam.lr = gam(I(wage&gt;250) ~ year+s(age,5)+education, family=binomial, data=Wage)\npar(mfrow=c(1,3))\nplot(gam.lr,se=T,col=\"green\")\n\ngam.lr.s = gam(I(wage&gt;250) ~ year+s(age,5)+education, family=binomial, data=Wage, \n               subset=(education!=\"1. &lt; HS Grad\"))\nplot(gam.lr.s,se=T,col=\"green\")\n</code></pre>"},{"location":"day4_new/","title":"CARET-Day","text":"<p>In this section, you will find the R code that we will use during the course. We will explain the code and output during correction of the exercises.</p> <p>After having completed this chapter you will be able to:</p> <ul> <li>Understand Sensitivity, Specificity, ROC curve and AUC </li> <li>Understand different regularisation method </li> <li>Understand K-fold cross-validation </li> <li>Understand Leave-one-out validation</li> <li>Understand how to built a signature</li> <li>Understand KNN-method</li> <li>Understand Random Forests</li> </ul> <p>Slides of lectures:</p> <p>Download slides morning Download slides afternoon</p>"},{"location":"day4_new/#alzheimer-data","title":"Alzheimer Data","text":"<p>Washington University conducted a clinical study to determine if biological measurements made from cerebrospinal fluid (CSF) can be used to diagnose or predict Alzheimer\u2019s disease (\u201cCraig-Schapiro, R., et al. (2011). Multiplexed Immunoassay Panel Identifies Novel CSF Biomarkers for Alzheimer\u2019s Disease Diagnosis and Prognosis. PLoS ONE, 6(4), e18850.\u201d). These data are a modified version of the values used for the publication.</p> <p>The R factor vector diagnosis contains the outcome data for 333 of the subjects. The demographic and laboratory results are collected in the data frame predictors.</p> <p>One important indicator of Alzheimer\u2019s disease is the genetic background of a subject. In particular, what versions of the Apolipoprotein E gene inherited from one\u2019s parents has an association with the disease. There are three variants of the gene: E2, E3 and E4. Since a child inherits a version of the gene from each parent, there are six possible combinations (e.g. E2/E2, E2/E3, and so on). This data is contained in the predictor column named Genotype.</p> <p>First we set for this exercise the libraries that we will need and load the data which is part of the AppliedPredictiveModeling package and is called AlzheimerDisease.</p> <pre><code>library(caret)\nlibrary(pROC)\nlibrary(ROCR)\nlibrary(AppliedPredictiveModeling)\ndata(AzheimerDisease)\n\nalzheimer &lt;- cbind(predictors,diagnosis)\nsummary(alzheimer) ## realize male is not a factor\nalzheimer$male &lt;- as.factor(alzheimer$male)\n</code></pre>"},{"location":"day4_new/#data-splitting","title":"Data Splitting","text":"<p>We first start by splitting the data into a training and a test set.</p> <p>The test set will be used only after having decided on the best model.</p> <p>Within the training set however we will again use a process of splitting and testing using cross validation.</p> <p>It is important to set a seed in order to be reproducible.</p> <pre><code>set.seed(3456)\ntrainIndex &lt;- createDataPartition(alzheimer$diagnosis, p = .8, \n                                  list = FALSE, \n                                  times = 1)\ndim(trainIndex)\ndim(alzheimer)\nalzheimerTrain &lt;- alzheimer[ trainIndex,]\nalzheimerTest  &lt;- alzheimer[-trainIndex,]\n</code></pre> <p>Try to understand how the test and training set is distributed in terms of control and impaired patients.</p> <pre><code>table(alzheimerTrain$diagnosis)\n\ntable(alzheimerTest$diagnosis)\n\ntable(alzheimer$diagnosis)\n</code></pre> <p>In some cases there is an important qualitative factor in the data that should be considered during (re)sampling. For example:</p> <p>in clinical trials, there may be hospital-to-hospital differences with longitudinal or repeated measures data, subjects (or general independent experimental unit) may have multiple rows in the data set, etc. There may be an interest in making sure that these groups are not contained in the training and testing set since this may bias the test set performance to be more optimistic. Also, when one or more specific groups are held out, the resampling might capture the \u201cruggedness\u201d of the model. In the example where clinical data is recorded over multiple sites, the resampling performance estimates partly measure how extensible the model is across sites.</p>"},{"location":"day4_new/#performance-measures-using-cross-validation","title":"Performance measures using Cross-Validation","text":"<p>We start by choosing the parameters of the trainControl function in order to do cross-Validation (CV). For that we need to choose the number of folds of the cross-validation.</p> <pre><code>fitControl_CV_accuracy &lt;- trainControl(## 5-fold CV\n                           method = \"cv\",\n                           number = 5\n                          )\n</code></pre> <p>We can also do repeated CV (RCV) which repeats the process of folds, n number of times.</p> <p><pre><code>fitControl_RCV_accuracy &lt;- trainControl(\n                           method = \"repeatedcv\",\n                           number = 5,\n                           repeats= 10\n                          )\n</code></pre> We could also choose ourselves the folds using the function  It is important to use the set the classProbs = TRUE in order to have in each folds controls and impared samples. <pre><code>folds &lt;- createFolds(y = alzheimerTrain$diagnosis, k = 5, returnTrain = TRUE)\nfitControl_CV_folds &lt;- trainControl(## 5-fold CV\n                           method = \"cv\",\n                           number = 5,\n                           index= folds)\n</code></pre></p> <p>We can also estimate ROC curves, as well as sensitivity and specificity on our training set.</p> <pre><code>fitControl_CV_ROC &lt;- trainControl(## 5-fold CV\n                           method = \"cv\",\n                           number = 5,\n                      classProbs = TRUE,    # Needed for ROC\n  summaryFunction = twoClassSummary )       # Needed for ROC\n</code></pre> <p>\u2026 or with repeated CV \u2026</p> <pre><code>fitControl_RCV_ROC &lt;- trainControl(## 5-fold CV\n                           method = \"repeatedcv\",\n                           number = 5,\n                           repeats= 10,\n                      classProbs = TRUE,    # Needed for ROC\n  summaryFunction = twoClassSummary )       # Needed for ROC\n</code></pre> <p>Optionally one can also save the predictions in each repeat using the \u201csavePrediction\u201d option. </p> <pre><code>fitControl_RCV_ROC_PRED &lt;- trainControl(## 5-fold CV\n                           method = \"repeatedcv\",\n                           number = 5,\n                           repeats= 10,\n                          savePredictions = \"final\",\n                      classProbs = TRUE,   # Needed for ROC\n  summaryFunction = twoClassSummary )   # Needed for ROC\n</code></pre> <p>The trainControl function is the function that can do it all, from bayesian Models to GAMs, but also regularizations amongst others. Have a look at the help in the caret tutorial book! We will see some other trainControl functions and methods later, such as regularization for example, which will be explained in a later exercise. </p> <p>Now, to find the best model according to the chosen method with the trainControl, we use the \u201ctrain\u201d function from the caret package. We need to provide the predictor and outcome data objects, as well as the method used. As we want to fit the binomial data and look at the performance, we need to use the option family=binomial(link=\u201dlogit\u201d) and the method glm. We can use the first column as a predictor for this exercise. </p> <p>By default for classification data it will choose the Accuracy as the method for performance measure. </p> <p>We start by using the default.</p> <pre><code>glmFit1 &lt;- train(diagnosis ~ ACE_CD143_Angiotensin_Converti, data = alzheimerTrain, \n                 method = \"glm\", \n                 family=binomial(link=\"logit\"),\n                 trControl = fitControl_CV_accuracy\n                 )\n</code></pre> <p>To look at the output we can first look at the summary of the glm</p> <pre><code>summary(glmFit1)\n</code></pre> <p>We realise that this is the same as performing our standard glm</p> <pre><code>summary(glm(diagnosis ~ ACE_CD143_Angiotensin_Converti, data = alzheimerTrain, \n  family=binomial(link=\"logit\")))\n</code></pre> <p>Now let us check how the accuracy was calculated and how we can now be confident about the estimation of the performance in this case</p> <pre><code>glmFit1$results\n</code></pre> <p>We can also look at individual Accuracy measurements in each of the folds</p> <pre><code>glmFit1$resample\n</code></pre> <p>And then we can see that the Accuracy in the results section is just the average of the Accuracy in each of the folds.</p> <pre><code>mean(glmFit1$resample$Accuracy)\n</code></pre> <p>Let us do the fit now with the repeated CV</p> <pre><code>glmFit2 &lt;- train(diagnosis ~ ACE_CD143_Angiotensin_Converti, data = alzheimerTrain, \n                 method = \"glm\", \n                 family=binomial(link=\"logit\"),\n                 trControl = fitControl_RCV_accuracy\n                 )\n</code></pre> <p>Check what it changed in the section \u201cresample\u201d!</p> <p>Now we can change the default measure if instead of the accuracy we would like to know more about the variability of the sensitivity and specificity. For that we only need to change the trControl with the appropriate control function and we will know.</p> <pre><code>glmFit3 &lt;- train(diagnosis ~ ACE_CD143_Angiotensin_Converti, data = alzheimerTrain, \n                 method = \"glm\", \n                 family=binomial(link=\"logit\"),\n                 trControl = fitControl_RCV_ROC\n                 )\n</code></pre> <p>You must have gotten a Warning message, why ? </p> Answer <p>The default metric is Accuracy and not ROC, this is therefore just a warning saying you forgot to change the metric parameter. Here is how it would be correct <pre><code>glmFit3 &lt;- train(diagnosis ~ ACE_CD143_Angiotensin_Converti, data = alzheimerTrain, \n             method = \"glm\", \n             family=binomial(link=\"logit\"),\n             trControl = fitControl_RCV_ROC,\n             metric=\"ROC\"\n             )\n</code></pre></p> <p>Now check the result section  <pre><code>glmFit3$results\n</code></pre></p> <p>We can now read clearly the ROC (or average ROC on our folds), as well as Sensitivity and Specificity. What can you conclude ?</p> <p>And what changes if you use the \u201cfitControl_RCV_ROC_PRED\u201d ?</p> Answer <p><pre><code>glmFit4 &lt;- train(diagnosis ~ ACE_CD143_Angiotensin_Converti, data = alzheimerTrain, \n             method = \"glm\", \n             family=binomial(link=\"logit\"),\n             trControl = fitControl_RCV_ROC_PRED,\n             metric=\"ROC\"\n             )\n\nglmFit4$pred             \n</code></pre> This is so useful as you can assess how many times each sample is classified wrongly or correctly and in which fold, so dependant on which samples. This helps in spotting which samples would benefit from another model and also helps creating new hypotheses. </p> <p>Bonus let us make a loop of all possible predictors in uni-variate analysis and  check which one has the best p-value and good ROC.</p> Answer <pre><code>col_num &lt;- dim(alzheimer)[2]-1 # we do not use the last column for prediction\npval &lt;- rep(0,col_num) \nrocval &lt;- rep(0,col_num)\nalzheimerTrain_temp &lt;- alzheimerTrain ## we create a temp copy of the alzheimer training data\nfor(i in 1:col_num){\ncolnames(alzheimerTrain_temp)[i] &lt;- \"temp\" ## create the column name that is temp \n\nglmFit1 &lt;- train(diagnosis ~ temp , data = alzheimerTrain_temp, \n             method = \"glm\", \n             family=\"binomial\",\n             trControl = fitControl_RCV_ROC,\n             metric=\"ROC\"\n             )\n\n   colnames(alzheimerTrain_temp)[i] &lt;- colnames(alzheimerTrain)[i]  #restore correct name         \n pval[i] &lt;- summary(glmFit1)$coefficients[,\"Pr(&gt;|z|)\"][2] ## store pvalue from GLM  \n rocval[i] &lt;- glmFit1$results$ROC  ## store ROC result\n}\n## careful we need to adjust the pvalues for multiple testing\n\npval_adj &lt;- p.adjust(pval)\nlength(pval_adj[pval_adj&lt;0.05])\n\ndata_results &lt;- data.frame(Name= colnames(alzheimerTrain)[-ncol(alzheimerTrain)], pval_adj = pval_adj, ROC= rocval)\n\ndata_results[data_results$pval_adj&lt;0.05,]\n\nnames_candidates &lt;- data_results[data_results$pval_adj&lt;0.05,\"Name\"]\n</code></pre> <p>We now have some candidates for multivariate analysis that look interesting, tau p_tau as well as Ab_42 where already known by the literature, which is a good indicator that the code works nicely!</p>"},{"location":"day4_new/#knn-method-imputing","title":"Knn-method (imputing)","text":"<p>Let us say we have some missing data in our dataset (we do not here so we will add some). <pre><code>alzheimerTrain_NA &lt;- alzheimerTrain\nrandom_rows &lt;- sample(1:nrow(alzheimerTrain), size = 30, replace = FALSE)\nrandom_cols &lt;- sample(1:(ncol(alzheimerTrain)-1), size = 30, replace = FALSE)\nfor(i in 1:30){\nalzheimerTrain_NA[random_rows[i],random_cols[i]] &lt;- NA\n}\nalzheimerTrain_NA[15,1]&lt;-NA\nsummary(alzheimerTrain_NA)\n</code></pre> By default glm in base R will give you an Error message if you have NAs <pre><code>glmFit4 &lt;- train(diagnosis ~ ACE_CD143_Angiotensin_Converti, data = alzheimerTrain_NA, \n                 method = \"glm\", \n                 family=binomial(link=\"logit\"),\n                 trControl = fitControl_RCV_ROC_PRED,\n                 metric=\"ROC\"\n                 )\n</code></pre></p> <p>So we need to do some imputation (or tell glm what to do with the NAs, via na.action = na.omit) <pre><code>glmFit4 &lt;- train(diagnosis ~ ACE_CD143_Angiotensin_Converti, data = alzheimerTrain_NA, \n                 method = \"glm\", \n                 family=binomial(link=\"logit\"),\n                 trControl = fitControl_RCV_ROC_PRED,\n                 metric=\"ROC\",\n                 na.action = na.omit\n                 )\n\nsummary(glmFit4)                 \n</code></pre></p> <p>What changed in the summary function ?</p> <p>Now this can be a problem if you have many parameters included and many NAs in different spots. Another way is imputation. With the train function this can be done easily. However knnImpute only works for numeric data. We can use it here by only selecting the numeric subset of the data. knnImpute is a function that can also be used outside of the train function, before running train. </p> <p>We use for that the function preProcess and the method knnImpute. We use the function predict to impute the values. And then combine with the output.  <pre><code>pre_proc &lt;- preProcess(alzheimerTrain_NA[,setdiff(colnames(alzheimerTrain_NA),c(\"male\",\"Genotype\",\"diagnosis\"))], method = c(\"center\", \"scale\", \"knnImpute\"))\n\npredictors_imputed &lt;- predict(pre_proc, newdata = alzheimerTrain_NA[,setdiff(colnames(alzheimerTrain_NA),c(\"male\",\"Genotype\",\"diagnosis\"))])\n\n# Combine with untouched outcome\ndata_imputed &lt;- cbind(predictors_imputed, diagnosis = alzheimerTrain_NA$diagnosis)\n\n\nglmFit4 &lt;- train(diagnosis ~ ACE_CD143_Angiotensin_Converti, data = data_imputed, \n                 method = \"glm\", \n                 family=binomial(link=\"logit\"),\n                 trControl = fitControl_CV_ROC,\n                 metric=\"ROC\"\n                # ,\n                 # preProcess =  c(\"center\", \"scale\", \"knnImpute\") if only numeric data this works best\n                 )\n\nsummary(glmFit4)                 \n</code></pre></p>"},{"location":"day4_new/#lasso-regularisation","title":"Lasso-Regularisation","text":"<p>There are three types of regularisations that we will try. We will start with the lasso method.</p> <p>It is always recommanded not to start with too many features in order for the method to perform better. </p> <p>Therefore we will try it but only on the candidate features we have chosen in the previous step. In gene expression data, you could start with doing a DGE between the two groups to find a candidate list of genes to select for creating a model. It is okay to do so here as we are only working on our training data. </p> <p>We start by using the glmnet package and the glmnet function and find the best model</p> <p><pre><code>library(glmnet)\nlasso_model &lt;- glmnet(y= alzheimerTrain$diagnosis, x=alzheimerTrain[,names_candidates] , family = \"binomial\", alpha = 1)  # alpha = 1 is LASSO\n\n# Plot coefficient paths\nplot(lasso_model, xvar = \"lambda\", label = TRUE)\n</code></pre> Then we can use cross validation to choose the best lambda</p> <pre><code># Cross-validated LASSO\ny_numeric &lt;- ifelse(alzheimerTrain$diagnosis == \"Impaired\", 1, 0)\ncv_lasso &lt;- cv.glmnet(y=y_numeric , x=as.matrix(alzheimerTrain[,names_candidates]), family = \"binomial\", alpha = 1, nfolds = 10)\n\n# Plot cross-validation curve\nplot(cv_lasso)\n\n# Best lambda\nbest_lambda &lt;- cv_lasso$lambda.min\n</code></pre> <p>You can now observe how the coefficients are estimated from the CV lasso method</p> <pre><code>coefs &lt;- coef(cv_lasso, s = \"lambda.min\")\ncoefs\n</code></pre> <p>We then select the variables that are not 0 and create our final model. We can do this with standard glm or again with performance validation.</p> <pre><code>selected_vars &lt;- rownames(coefs)[which(coefs != 0)][-1]\nalzheimer_selected &lt;- as.matrix(alzheimerTrain[, selected_vars])\nglm_fit &lt;- glm(alzheimerTrain$diagnosis ~ alzheimer_selected, family = \"binomial\")\n</code></pre> <p>And then we have a look at the results</p> <pre><code>summary(glm_fit)\n</code></pre> <p>We see that the coefficients for the selected columns are not alll significant. Why ?</p> <p>We will now use the caret package to have results for performance as well as model optimization. </p> <pre><code>lasso_caret &lt;- train(diagnosis ~ Alpha_1_Antitrypsin + B_Lymphocyte_Chemoattractant_BL + FAS + Fibrinogen + GRO_alpha + Gamma_Interferon_induced_Monokin + IL_7 + MIF + MMP10 + MMP7 + NT_proBNP + PAI_1 + Pancreatic_polypeptide + TRAIL_R3 + tau + p_tau + Ab_42, data = alzheimerTrain, \n                 method = \"glmnet\", \n                  family=\"binomial\",\n                  trControl = fitControl_CV_ROC,\n                  metric=\"ROC\",\n                  tuneGrid = expand.grid(\n    alpha = 1,             # LASSO (alpha = 1)\n    lambda = 10^seq(-4, 1, length = 50)  # search over lambda\n  )\n )  \n</code></pre> <p>We can see that based on ROC not the same lambda is selected. </p> <pre><code>lasso_caret$bestTune$lambda\nbest_lambda\n</code></pre> <p><pre><code>lasso_model_caret_final &lt;- glmnet(y= alzheimerTrain$diagnosis, x=alzheimerTrain[,names_candidates] , family = \"binomial\", alpha = 1,lambda=lasso_caret$bestTune$lambda)\n\ncoefs &lt;- coef(lasso_model_caret_final)\nselected_vars_caret &lt;- rownames(coefs)[which(coefs != 0)][-1]\nunique(selected_vars_caret == selected_vars)\n</code></pre> Therefore all the same variables have been selected.</p>"},{"location":"day4_new/#ridge-regression","title":"Ridge regression","text":"<p>Do the same now with Ridge regression.</p> Answer <p>We start by using the glmnet package and the glmnet function and find the best model</p> <p><pre><code>ridge_model &lt;- glmnet(y= alzheimerTrain$diagnosis, x=alzheimerTrain[,names_candidates] , family = \"binomial\", alpha = 0)  # alpha = 0 is Ridge\n\n# Plot coefficient paths\nplot(ridge_model, xvar = \"lambda\", label = TRUE)\n</code></pre> Then we can use cross validation to choose the best lambda</p> <pre><code># Cross-validated Ridge\ny_numeric &lt;- ifelse(alzheimerTrain$diagnosis == \"Impaired\", 1, 0)\ncv_ridge &lt;- cv.glmnet(y=y_numeric , x=as.matrix(alzheimerTrain[,names_candidates]), family = \"binomial\", alpha = 0, nfolds = 10)\n\n# Plot cross-validation curve\nplot(cv_ridge)\n\n# Best lambda\nbest_lambda &lt;- cv_ridge$lambda.min\n</code></pre> <p>You can now observe how the coefficients are estimated from the CV lasso method</p> <pre><code>coefs &lt;- coef(cv_ridge, s = \"lambda.min\")\ncoefs\n</code></pre> <p>We then select the variables that are not 0 and create our final model. We can do this with standard glm or again with performance validation.</p> <pre><code>selected_vars &lt;- rownames(coefs)[which(coefs != 0)][-1]\nalzheimer_selected &lt;- as.matrix(alzheimerTrain[, selected_vars])\nglm_fit &lt;- glm(alzheimerTrain$diagnosis ~ alzheimer_selected, family = \"binomial\")\n</code></pre> <p>And then we have a look at the results</p> <pre><code>summary(glm_fit)\n</code></pre> <p>We see that the coefficients for the selected columns are not alll significant. Why ?</p> <p>We will now use the caret package to have results for performance as well as model optimization. </p> <pre><code>ridge_caret &lt;- train(diagnosis ~ Alpha_1_Antitrypsin + B_Lymphocyte_Chemoattractant_BL + FAS + Fibrinogen + GRO_alpha + Gamma_Interferon_induced_Monokin + IL_7 + MIF + MMP10 + MMP7 + NT_proBNP + PAI_1 + Pancreatic_polypeptide + TRAIL_R3 + tau + p_tau + Ab_42, data = alzheimerTrain, \nmethod = \"glmnet\", \nfamily=\"binomial\",\ntrControl = fitControl_CV_ROC,\nmetric=\"ROC\",\ntuneGrid = expand.grid(\nalpha = 0,             # Ridge (alpha = 0)\nlambda = 10^seq(-4, 1, length = 50)  # search over lambda\n)\n)  \n</code></pre> <p>We can see that based on ROC not the same lambda is selected. </p> <pre><code>ridge_caret$bestTune$lambda\nbest_lambda\n</code></pre> <p><pre><code>ridge_model_caret_final &lt;- glmnet(y= alzheimerTrain$diagnosis, x=alzheimerTrain[,names_candidates] , family = \"binomial\", alpha = 0,lambda=ridge_caret$bestTune$lambda)\n\ncoefs &lt;- coef(ridge_model_caret_final)\nselected_vars_caret &lt;- rownames(coefs)[which(coefs != 0)][-1]\nunique(selected_vars_caret == selected_vars)\n</code></pre> Therefore all the same variables have been selected.</p>"},{"location":"day4_new/#elastic-net","title":"Elastic Net","text":"<p>Do the same now with Elastic net regression. You will now see a difference in the caret function.</p> Answer <p>We start by using the glmnet package and the glmnet function and find the best model</p> <p><pre><code>elastic_model &lt;- glmnet(y= alzheimerTrain$diagnosis, x=alzheimerTrain[,names_candidates] , family = \"binomial\", alpha = 0.5)  # alpha between 0 and 1 is Elastic net\n\n# Plot coefficient paths\nplot(elastic_model, xvar = \"lambda\", label = TRUE)\n</code></pre> Then we can use cross validation to choose the best lambda</p> <pre><code># Cross-validated Ridge\ny_numeric &lt;- ifelse(alzheimerTrain$diagnosis == \"Impaired\", 1, 0)\ncv_elastic &lt;- cv.glmnet(y=y_numeric , x=as.matrix(alzheimerTrain[,names_candidates]), family = \"binomial\", alpha = 0.5, nfolds = 10)\n\n# Plot cross-validation curve\nplot(cv_elastic)\n\n# Best lambda\nbest_lambda &lt;- cv_elastic$lambda.min\n</code></pre> <p>You can now observe how the coefficients are estimated from the CV lasso method</p> <pre><code>coefs &lt;- coef(cv_elastic, s = \"lambda.min\")\ncoefs\n</code></pre> <p>We then select the variables that are not 0 and create our final model. We can do this with standard glm or again with performance validation.</p> <pre><code>selected_vars &lt;- rownames(coefs)[which(coefs != 0)][-1]\nalzheimer_selected &lt;- as.matrix(alzheimerTrain[, selected_vars])\nglm_fit &lt;- glm(alzheimerTrain$diagnosis ~ alzheimer_selected, family = \"binomial\")\n</code></pre> <p>And then we have a look at the results</p> <pre><code>summary(glm_fit)\n</code></pre> <p>We see that the coefficients for the selected columns are not alll significant. Why ?</p> <p>We will now use the caret package to have results for performance as well as model optimization. The train function can optimize alpha and lambda.</p> <pre><code>elastic_caret &lt;- train(diagnosis ~ Alpha_1_Antitrypsin + B_Lymphocyte_Chemoattractant_BL + FAS + Fibrinogen + GRO_alpha + Gamma_Interferon_induced_Monokin + IL_7 + MIF + MMP10 + MMP7 + NT_proBNP + PAI_1 + Pancreatic_polypeptide + TRAIL_R3 + tau + p_tau + Ab_42, data = alzheimerTrain, \nmethod = \"glmnet\", \nfamily=\"binomial\",\ntrControl = fitControl_CV_ROC,\nmetric=\"ROC\",\ntuneGrid = expand.grid(\nalpha = seq(0,1,length=20),             # Ridge (alpha = 0)\nlambda = 10^seq(-4, 1, length = 50)  # search over lambda\n)\n)  \n</code></pre> <p>We can see that based on ROC not the same lambda is selected and the best alpha selected is neither 1 nor 0 nor 0.5</p> <pre><code>elastic_caret$bestTune$lambda\nbest_lambda\nelastic_caret$bestTune$alpha\n</code></pre> <p><pre><code>elastic_model_caret_final &lt;- glmnet(y= alzheimerTrain$diagnosis, x=alzheimerTrain[,names_candidates] , family = \"binomial\", alpha = elastic_caret$bestTune$alpha,lambda=elastic_caret$bestTune$lambda)\n\ncoefs &lt;- coef(ridge_model_caret_final)\nselected_vars_caret &lt;- rownames(coefs)[which(coefs != 0)][-1]\nunique(selected_vars_caret == selected_vars)\n</code></pre> Therefore all the same variables have been selected.</p>"},{"location":"day4_new/#leave-one-out-method","title":"Leave-one-out method","text":"<p>Try the leave-one-out method. Where do you need to adapt the code in the Control or the train function ?</p> Answer <pre><code>fitControl_LOOCV_ROC &lt;- trainControl(## 5-fold CV\n                      method = \"LOOCV\",\n                      number = 5,\n                 classProbs = TRUE,    # Needed for ROC\n summaryFunction = twoClassSummary )   \n</code></pre>"},{"location":"day4_new/#random-forest","title":"Random Forest","text":"<p>Again for random forest we can just process everything the same way but specifying that we want to use random forest or rf, but where ? changing the train or the control function?</p> Answer <p><pre><code>rf_caret &lt;- train(diagnosis ~ Alpha_1_Antitrypsin + B_Lymphocyte_Chemoattractant_BL + FAS + Fibrinogen + GRO_alpha + Gamma_Interferon_induced_Monokin + IL_7 + MIF + MMP10 + MMP7 + NT_proBNP + PAI_1 + Pancreatic_polypeptide + TRAIL_R3 + tau + p_tau + Ab_42, data = alzheimerTrain, \nmethod = \"rf\", \ntrControl = fitControl_CV_ROC,\nmetric=\"ROC\",\ntuneLength = 5\n)  \n\nprint(rf_caret)\n</code></pre> Have now a look at the plot with the parameters</p> <pre><code>plot(rf_caret)\n</code></pre> <p>One can have a look at the importance of the variables </p> <pre><code>var_imp &lt;- varImp(rf_caret)\nprint(var_imp)\n</code></pre> <p>So with Random forest the method selects Ab_42, tau, p_tau, MMP10 and IL_7.</p> <p>Bonus :  One can visualise random forest trees using the reprtree package </p> <pre><code>final_rf &lt;- rf_caret$finalModel\nlibrary(reprtree)\n\nrf &lt;- randomForest(diagnosis ~ Ab_42 + tau + p_tau + MMP10 + IL_7, data = alzheimerTrain, ntree = 10)\n\n\nreprtree::plot.getTree(rf, k = 1) ## difficult to visulize but in other datasets could be important\n</code></pre>"},{"location":"exam/","title":"Exam","text":""},{"location":"exam/#exam","title":"EXAM","text":"<p>The participants who need credits must answer the following questions and send the results as an R script with comments to rachel.marcone@sib.swiss until latest Friday 12th of September 2025.</p> <p>Download exercise material</p>"},{"location":"exam/#birthwt-dataset","title":"Birthwt dataset","text":"<ol> <li> <p>Load the birthwt dataset from the MASS package and describe the variables that are reported in this dataset Explore the variability in this dataset and the relationship between the variables</p> </li> <li> <p>Fit a model to predict birth weight using mother\u2019s age</p> </li> <li> <p>Check the regression assumptions</p> </li> <li> <p>Get the confidence interval and the prediction interval of the regression model</p> </li> <li> <p>Fit a model to predict birth weight using mother\u2019s age, mother\u2019s weight and smoking status Is this new model providing a better fit to the data ?</p> </li> <li> <p>Check the regression assumptions</p> </li> <li> <p>Fit a model to predict the variable birth weight below 2500 g using mother\u2019s age what is the type of the response variable ? Can you use a simple linear regression model ? Why ?</p> </li> <li> <p>Fit a model to find the parameters which explain the probability of birth weight below 2500 g ?</p> </li> <li> <p>Check the regression assumptions</p> </li> </ol>"},{"location":"exam/#fossil-dataset","title":"Fossil dataset","text":"<ol> <li> <p>Load the fossil dataset from the SemiPar package and describe the variables that are reported in this dataset Explore the variability in this dataset and the relationship between the variables.</p> </li> <li> <p>Fit a polynomial model to predict strontium ratio using age Use different degrees of polynomial model which model better fit your data ? Why ?</p> </li> <li> <p>Fit a smoothing spline to predict strontium ratio using age Does it look better than the best polynomial model ? Why ?</p> </li> <li> <p>Fit a local regression model (for instance using LOESS) to predict strontium ratio using age Does it look better than the smoothing spline ? Why ?</p> </li> <li> <p>Load the dragons dataset from Gabriela K Hajduk and Liam Bailey Explore the variability in this dataset and the relationship between the variables</p> </li> <li> <p>Fit a simple linear model to predict test score from body length and check the regression assumptions What could be wrong with this model ?</p> </li> <li> <p>Fit a model that would be more appropriate for this dataset to predict test score from body length  Interpret the results of your model Check the regression assumptions</p> </li> </ol>"},{"location":"links/","title":"Links that are useful","text":"<p>https://www.statlearning.com/, a book to be downloaded to learn statistics and apply in R.</p> <p>https://towardsdatascience.com/maximum-likelihood-ml-vs-reml-78cf79bef2cf, a mathematical explanation showing the difference between ML and REML with exact formulas.</p> <p>https://topepo.github.io/caret/, package for cross-validation or leave-one-out</p> <p>GLMnet and penalized are packages for penalization and regularization : https://glmnet.stanford.edu/articles/glmnet.html and https://cran.r-project.org/web/packages/penalized/index.html</p> <p>https://rpubs.com/yjunechoe/correlationsLMEM, about correlation in mixed-effect models</p> <p>https://library.virginia.edu/data/articles/understanding-deviance-residuals, understanding deviance residuals</p> <p>formula for acf https://www.sciencedirect.com/topics/chemistry/autocorrelation-function</p> <p>https://stats.stackexchange.com/questions/92394/checking-residuals-for-normality-in-generalised-linear-models on checking normality in GLMs</p> <p>comparison of link functions https://watermark.silverchair.com/020083_1_online.pdf</p>"},{"location":"precourse/","title":"Precourse preparation","text":""},{"location":"precourse/#previous-knowledge","title":"Previous knowledge","text":"<p>As is stated in the course prerequisites on the announcement web page, this course is intended for people already familiar with basic statistics and R. Participants must be comfortable with topics such as hypothesis testing, correlation and linear models, and must have a prior knowledge of the \u201cR\u201d language and environment for statistical computing and graphics. Participants who have already followed the SIB course \u201cIntroduction to statistics with R\u201d or an equivalent course, and have used its content in practice should fit this prerequisite.</p> <p>Before applying to this course, please self-assess your knowledge in stats and R to make sure this course is right for you. Here are 2 quizzes:</p> <p>https://gohighbrow.com/quiz-introduction-to-statistics/</p> <p>https://docs.google.com/forms/d/e/1FAIpQLSfXCnmLha0Ks4ZZZ42G_5MyIbGi-JhPayuHZ_P2jdXZEtXdqg/viewform</p>"},{"location":"precourse/#technical","title":"Technical","text":"<p>To do the exercises, you are required to have your own computer with at least 4 Gb of RAM and with an internet connection, as well as the latest the version of R and the free version of RStudio installed.</p> <p>Please, install the necessary packages using:</p> <pre><code>install.packages(\"akima\")\ninstall.packages(\"car\")\ninstall.packages(\"DAAG\")\ninstall.packages(\"faraway\")\ninstall.packages(\"gam\")\ninstall.packages(\"ggplot2\")\ninstall.packages(\"ISwR\")\ninstall.packages(\"lattice\")\ninstall.packages(\"lme4\")\ninstall.packages(\"nlme\")\ninstall.packages(\"SemiPar\")\ninstall.packages(\"splines\")\ninstall.packages(\"statmod\")\ninstall.packages(\"WWGbook\")\ninstall.packages(\"caret\")\ninstall.packages(\"glmnet\")\ninstall.packages(\"ROCR\")\ninstall.packages(\"pROC\")\ninstall.packages(AppliedPredictiveModeling)\n#devtools::install_github('araastat/reprtree') # this is optional\n</code></pre>"}]}